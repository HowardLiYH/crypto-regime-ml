{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f16fbe8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.1.2-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages (from xgboost) (2.2.6)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages (from xgboost) (1.16.2)\n",
      "Downloading xgboost-3.1.2-py3-none-macosx_12_0_arm64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fc32d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report,\n",
    "    precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, precision_recall_curve,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Non-interactive backend\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# XGBoost imports\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"WARNING: XGBoost not installed. Install with: pip install xgboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62d5f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# CONFIGURATION\n",
    "# =========================================\n",
    "DATA_DIR = Path(\"/Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data\")\n",
    "FILES = {\n",
    "    \"BTC\": DATA_DIR / \"Bybit_BTC.csv\",\n",
    "    \"ETH\": DATA_DIR / \"Bybit_ETH.csv\",\n",
    "    \"SOL\": DATA_DIR / \"Bybit_SOL.csv\",\n",
    "    \"XRP\": DATA_DIR / \"Bybit_XRP.csv\",\n",
    "    \"DOGE\": DATA_DIR / \"Bybit_DOGE.csv\",\n",
    "}\n",
    "\n",
    "HORIZONS = [1, 3, 6]  # Forecast horizons in 4-hour bars\n",
    "DEFAULT_COST_BP = {1: 8.0, 3: 10.0, 6: 12.0}  # Trading costs in basis points\n",
    "\n",
    "# Policy thresholds\n",
    "TAU_P = 0.60        # Probability gate for P(edge > cost)\n",
    "TAU_MU = 0.0005     # Expected-return gate (log-return)\n",
    "LAM = 2.0           # Kelly-lite multiplier\n",
    "W_MAX = 0.50        # Max gross position (50% notional)\n",
    "\n",
    "MODEL_VERSION = \"xgboost_multiH_v1.0\"\n",
    "CALIBRATION_VERSION = \"iso+conformal_v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3c32115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# UTILITY FUNCTIONS\n",
    "# =========================================\n",
    "def bp_to_logret(bp: float) -> float:\n",
    "    \"\"\"Convert basis points to log-return units.\"\"\"\n",
    "    return bp * 1e-4\n",
    "\n",
    "\n",
    "def _find_close_column(df: pd.DataFrame) -> str:\n",
    "    \"\"\"Find the close price column in a dataframe.\"\"\"\n",
    "    lower = {c.lower(): c for c in df.columns}\n",
    "    for key in (\"close\", \"closing_price\", \"close_price\", \"price_close\", \"last\", \"c\"):\n",
    "        if key in lower:\n",
    "            return lower[key]\n",
    "    # Fallback: any single float column\n",
    "    float_cols = [c for c in df.columns if pd.api.types.is_float_dtype(df[c])]\n",
    "    if len(float_cols) == 1:\n",
    "        return float_cols[0]\n",
    "    raise ValueError(\"Cannot identify 'close' column.\")\n",
    "\n",
    "\n",
    "def cumulative_log_returns(price: pd.Series, h: int) -> pd.Series:\n",
    "    \"\"\"Compute log(P_{t+h}/P_t) aligned to t.\"\"\"\n",
    "    return np.log(price.shift(-h) / price).dropna()\n",
    "\n",
    "\n",
    "def brier_score(y: np.ndarray, p: np.ndarray) -> float:\n",
    "    \"\"\"Brier score for probability calibration.\"\"\"\n",
    "    return float(np.mean((y - p) ** 2))\n",
    "\n",
    "\n",
    "def expected_calibration_error(y: np.ndarray, p: np.ndarray, bins: int = 10) -> float:\n",
    "    \"\"\"Expected Calibration Error (ECE).\"\"\"\n",
    "    edges = np.linspace(0, 1, bins + 1)\n",
    "    ece = 0.0\n",
    "    for i in range(bins):\n",
    "        m = (p >= edges[i]) & (p < edges[i+1])\n",
    "        if m.sum() == 0:\n",
    "            continue\n",
    "        ece += (m.sum()/len(p)) * np.abs(np.mean(y[m]) - np.mean(p[m]))\n",
    "    return float(ece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685f0538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# EVALUATION METRICS\n",
    "# =========================================\n",
    "def compute_classification_metrics(y_true: np.ndarray, y_pred: np.ndarray,\n",
    "                                   y_prob: np.ndarray = None) -> dict:\n",
    "    \"\"\"Compute comprehensive classification metrics.\"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    metrics['confusion_matrix'] = cm\n",
    "    metrics['true_negatives'] = int(tn)\n",
    "    metrics['false_positives'] = int(fp)\n",
    "    metrics['false_negatives'] = int(fn)\n",
    "    metrics['true_positives'] = int(tp)\n",
    "\n",
    "    # Basic metrics\n",
    "    metrics['accuracy'] = float((tp + tn) / (tp + tn + fp + fn))\n",
    "    metrics['precision'] = precision_score(y_true, y_pred, zero_division=0)\n",
    "    metrics['recall'] = recall_score(y_true, y_pred, zero_division=0)\n",
    "    metrics['f1_score'] = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    # Additional metrics\n",
    "    metrics['specificity'] = float(tn / (tn + fp)) if (tn + fp) > 0 else 0.0\n",
    "    metrics['false_positive_rate'] = float(fp / (fp + tn)) if (fp + tn) > 0 else 0.0\n",
    "    metrics['false_negative_rate'] = float(fn / (fn + tp)) if (fn + tp) > 0 else 0.0\n",
    "\n",
    "    # Balanced accuracy\n",
    "    metrics['balanced_accuracy'] = (metrics['recall'] + metrics['specificity']) / 2\n",
    "\n",
    "    # ROC-AUC if probabilities provided\n",
    "    if y_prob is not None and len(np.unique(y_true)) > 1:\n",
    "        try:\n",
    "            metrics['roc_auc'] = roc_auc_score(y_true, y_prob)\n",
    "            metrics['average_precision'] = average_precision_score(y_true, y_prob)\n",
    "        except:\n",
    "            metrics['roc_auc'] = None\n",
    "            metrics['average_precision'] = None\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def print_classification_report(metrics: dict, horizon: int, split: str = \"test\"):\n",
    "    \"\"\"Pretty print classification metrics.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"CLASSIFICATION METRICS - Horizon {horizon} ({split})\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = metrics['confusion_matrix']\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(f\"                Predicted Negative  Predicted Positive\")\n",
    "    print(f\"Actual Negative        {cm[0,0]:6d}              {cm[0,1]:6d}\")\n",
    "    print(f\"Actual Positive        {cm[1,0]:6d}              {cm[1,1]:6d}\")\n",
    "\n",
    "    # Metrics\n",
    "    print(f\"\\nPerformance Metrics:\")\n",
    "    print(f\"  Accuracy:           {metrics['accuracy']:.4f}\")\n",
    "    print(f\"  Balanced Accuracy:  {metrics['balanced_accuracy']:.4f}\")\n",
    "    print(f\"  Precision:          {metrics['precision']:.4f}\")\n",
    "    print(f\"  Recall (TPR):       {metrics['recall']:.4f}\")\n",
    "    print(f\"  Specificity (TNR):  {metrics['specificity']:.4f}\")\n",
    "    print(f\"  F1 Score:           {metrics['f1_score']:.4f}\")\n",
    "\n",
    "    if metrics.get('roc_auc') is not None:\n",
    "        print(f\"  ROC-AUC:            {metrics['roc_auc']:.4f}\")\n",
    "        print(f\"  Average Precision:  {metrics['average_precision']:.4f}\")\n",
    "\n",
    "    # Detailed counts\n",
    "    print(f\"\\nDetailed Counts:\")\n",
    "    print(f\"  True Positives:     {metrics['true_positives']}\")\n",
    "    print(f\"  True Negatives:     {metrics['true_negatives']}\")\n",
    "    print(f\"  False Positives:    {metrics['false_positives']}\")\n",
    "    print(f\"  False Negatives:    {metrics['false_negatives']}\")\n",
    "    print(f\"  Total Samples:      {metrics['true_positives'] + metrics['true_negatives'] + metrics['false_positives'] + metrics['false_negatives']}\")\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm: np.ndarray, horizon: int, save_path: Path = None):\n",
    "    \"\"\"Plot confusion matrix as heatmap.\"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Normalize for percentages\n",
    "    cm_pct = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "    # Create annotations\n",
    "    annot = np.array([[f'{cm[i,j]}\\n({cm_pct[i,j]:.1f}%)'\n",
    "                      for j in range(cm.shape[1])]\n",
    "                      for i in range(cm.shape[0])])\n",
    "\n",
    "    sns.heatmap(cm, annot=annot, fmt='', cmap='Blues',\n",
    "                xticklabels=['Negative', 'Positive'],\n",
    "                yticklabels=['Negative', 'Positive'],\n",
    "                cbar_kws={'label': 'Count'})\n",
    "\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.title(f'Confusion Matrix - Horizon {horizon}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"  Saved confusion matrix to: {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_roc_curve(y_true: np.ndarray, y_prob: np.ndarray,\n",
    "                   horizon: int, save_path: Path = None):\n",
    "    \"\"\"Plot ROC curve.\"\"\"\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        print(\"  Warning: Cannot plot ROC curve - only one class present\")\n",
    "        return\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "             label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--',\n",
    "             label='Random classifier')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate (Recall)')\n",
    "    plt.title(f'ROC Curve - Horizon {horizon}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"  Saved ROC curve to: {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_precision_recall_curve(y_true: np.ndarray, y_prob: np.ndarray,\n",
    "                                horizon: int, save_path: Path = None):\n",
    "    \"\"\"Plot precision-recall curve.\"\"\"\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        print(\"  Warning: Cannot plot PR curve - only one class present\")\n",
    "        return\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_prob)\n",
    "    avg_precision = average_precision_score(y_true, y_prob)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, color='darkorange', lw=2,\n",
    "             label=f'PR curve (AP = {avg_precision:.3f})')\n",
    "\n",
    "    # Baseline\n",
    "    baseline = np.sum(y_true) / len(y_true)\n",
    "    plt.axhline(y=baseline, color='navy', linestyle='--', lw=2,\n",
    "                label=f'Baseline (prevalence = {baseline:.3f})')\n",
    "\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - Horizon {horizon}')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"  Saved PR curve to: {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def save_metrics_to_csv(all_metrics: dict, save_path: Path):\n",
    "    \"\"\"Save metrics summary to CSV.\"\"\"\n",
    "    rows = []\n",
    "    for symbol, horizons in all_metrics.items():\n",
    "        for h, metrics in horizons.items():\n",
    "            row = {\n",
    "                'symbol': symbol,\n",
    "                'horizon': h,\n",
    "                'accuracy': metrics.get('accuracy', np.nan),\n",
    "                'balanced_accuracy': metrics.get('balanced_accuracy', np.nan),\n",
    "                'precision': metrics.get('precision', np.nan),\n",
    "                'recall': metrics.get('recall', np.nan),\n",
    "                'specificity': metrics.get('specificity', np.nan),\n",
    "                'f1_score': metrics.get('f1_score', np.nan),\n",
    "                'roc_auc': metrics.get('roc_auc', np.nan),\n",
    "                'avg_precision': metrics.get('average_precision', np.nan),\n",
    "                'brier_score': metrics.get('brier_val', np.nan),\n",
    "                'ece': metrics.get('ece_val', np.nan),\n",
    "                'true_positives': metrics.get('true_positives', 0),\n",
    "                'false_positives': metrics.get('false_positives', 0),\n",
    "                'true_negatives': metrics.get('true_negatives', 0),\n",
    "                'false_negatives': metrics.get('false_negatives', 0),\n",
    "            }\n",
    "            rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"\\nSaved metrics summary to: {save_path}\")\n",
    "\n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"OVERALL METRICS SUMMARY (across all symbols and horizons)\")\n",
    "    print(\"=\"*60)\n",
    "    summary_cols = ['accuracy', 'balanced_accuracy', 'precision', 'recall',\n",
    "                   'f1_score', 'roc_auc', 'brier_score', 'ece']\n",
    "    print(df[summary_cols].describe().round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8c689a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# FEATURE ENGINEERING\n",
    "# =========================================\n",
    "def make_feature_table(close: pd.Series):\n",
    "    \"\"\"Build feature table from close prices.\"\"\"\n",
    "    df = pd.DataFrame(index=close.index)\n",
    "    df[\"price\"] = close.astype(float)\n",
    "\n",
    "    # Log returns\n",
    "    df[\"ret_1\"] = np.log(df[\"price\"] / df[\"price\"].shift(1))\n",
    "    df[\"ret_3\"] = np.log(df[\"price\"] / df[\"price\"].shift(3))\n",
    "    df[\"ret_6\"] = np.log(df[\"price\"] / df[\"price\"].shift(6))\n",
    "\n",
    "    # Volatility\n",
    "    df[\"vol_6\"] = df[\"ret_1\"].rolling(6).std()\n",
    "    df[\"vol_12\"] = df[\"ret_1\"].rolling(12).std()\n",
    "\n",
    "    # Moving average ratio\n",
    "    ma_10 = df[\"price\"].rolling(10).mean()\n",
    "    ma_20 = df[\"price\"].rolling(20).mean()\n",
    "    df[\"ma_ratio\"] = np.log(ma_10 / ma_20)\n",
    "\n",
    "    # Drop NaN rows\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Feature matrix (exclude price)\n",
    "    feat_cols = [c for c in df.columns if c != \"price\"]\n",
    "    X = df[feat_cols].values.astype(float)\n",
    "\n",
    "    return df, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e7c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# WALK-FORWARD CV\n",
    "# =========================================\n",
    "def purged_walkforward_slices(n: int, n_folds: int = 3, embargo: int = 24):\n",
    "    \"\"\"Generate (train, val, test) slices for walk-forward CV.\"\"\"\n",
    "    fold_size = n // (n_folds + 2)\n",
    "    slices = []\n",
    "\n",
    "    for i in range(n_folds):\n",
    "        train_end = (i + 1) * fold_size\n",
    "        val_start = train_end + embargo\n",
    "        val_end = val_start + fold_size\n",
    "        test_start = val_end + embargo\n",
    "        test_end = min(test_start + fold_size, n)\n",
    "\n",
    "        if test_end - test_start < fold_size // 2:\n",
    "            break\n",
    "\n",
    "        slices.append((\n",
    "            (0, train_end),\n",
    "            (val_start, val_end),\n",
    "            (test_start, test_end)\n",
    "        ))\n",
    "\n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe6951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# XGBOOST MODEL\n",
    "# =========================================\n",
    "@dataclass\n",
    "class XGBSnapshot:\n",
    "    \"\"\"Container for trained XGBoost model.\"\"\"\n",
    "    booster: xgb.Booster\n",
    "    scaler: StandardScaler\n",
    "    horizon: int\n",
    "    feature_names: list[str]\n",
    "    best_iteration: int | None = None\n",
    "    feature_importance: dict | None = None\n",
    "\n",
    "\n",
    "def fit_xgboost_classifier(X_train: np.ndarray, y_train: np.ndarray,\n",
    "                           X_val: np.ndarray = None, y_val: np.ndarray = None,\n",
    "                           horizon: int = 1,\n",
    "                           feature_names: list[str] = None,\n",
    "                           random_state: int = 123,\n",
    "                           n_estimators: int = 100,\n",
    "                           max_depth: int = 6,\n",
    "                           learning_rate: float = 0.1,\n",
    "                           subsample: float = 0.8,\n",
    "                           colsample_bytree: float = 0.8,\n",
    "                           reg_alpha: float = 0.0,\n",
    "                           reg_lambda: float = 1.0,\n",
    "                           scale_pos_weight: float = None,\n",
    "                           early_stopping_rounds: int = 10) -> XGBSnapshot:\n",
    "    \"\"\"\n",
    "    Train XGBoost classifier with optional early stopping.\n",
    "\n",
    "    Args:\n",
    "        X_train: Training features\n",
    "        y_train: Training labels (binary)\n",
    "        X_val: Validation features (for early stopping)\n",
    "        y_val: Validation labels\n",
    "        horizon: Forecast horizon\n",
    "        feature_names: List of feature names\n",
    "        n_estimators: Number of boosting rounds (trees)\n",
    "        max_depth: Maximum tree depth\n",
    "        learning_rate: Step size shrinkage (eta)\n",
    "        subsample: Subsample ratio of training instances\n",
    "        colsample_bytree: Subsample ratio of columns per tree\n",
    "        reg_alpha: L1 regularization term on weights\n",
    "        reg_lambda: L2 regularization term on weights\n",
    "        scale_pos_weight: Balancing of positive/negative weights (auto if None)\n",
    "        early_stopping_rounds: Stop if no improvement for N rounds\n",
    "\n",
    "    Returns:\n",
    "        XGBSnapshot with trained model\n",
    "    \"\"\"\n",
    "    if not XGBOOST_AVAILABLE:\n",
    "        raise ImportError(\"XGBoost not installed. Run: pip install xgboost\")\n",
    "\n",
    "    # Auto-balance classes if not specified\n",
    "    if scale_pos_weight is None:\n",
    "        neg_count = np.sum(y_train == 0)\n",
    "        pos_count = np.sum(y_train == 1)\n",
    "        scale_pos_weight = neg_count / pos_count if pos_count > 0 else 1.0\n",
    "\n",
    "    # Standardize features (XGBoost doesn't require it, but helps with regularization)\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "    # Create DMatrix (XGBoost's internal data structure)\n",
    "    if feature_names is None:\n",
    "        feature_names = [f\"f{i}\" for i in range(X_train.shape[1])]\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train_scaled, label=y_train, feature_names=feature_names)\n",
    "\n",
    "    # Parameters\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'max_depth': max_depth,\n",
    "        'eta': learning_rate,\n",
    "        'subsample': subsample,\n",
    "        'colsample_bytree': colsample_bytree,\n",
    "        'alpha': reg_alpha,\n",
    "        'lambda': reg_lambda,\n",
    "        'scale_pos_weight': scale_pos_weight,\n",
    "        'seed': random_state,\n",
    "        'tree_method': 'auto',\n",
    "        'verbosity': 0  # Silent\n",
    "    }\n",
    "\n",
    "    # Early stopping setup\n",
    "    evals = [(dtrain, 'train')]\n",
    "    if X_val is not None and y_val is not None:\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "        dval = xgb.DMatrix(X_val_scaled, label=y_val, feature_names=feature_names)\n",
    "        evals.append((dval, 'val'))\n",
    "\n",
    "    # Train\n",
    "    evals_result = {}\n",
    "    bst = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=n_estimators,\n",
    "        evals=evals,\n",
    "        early_stopping_rounds=early_stopping_rounds if X_val is not None else None,\n",
    "        evals_result=evals_result,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    # Feature importance\n",
    "    importance_dict = bst.get_score(importance_type='gain')  # 'gain', 'weight', or 'cover'\n",
    "\n",
    "    return XGBSnapshot(\n",
    "        booster=bst,\n",
    "        scaler=scaler,\n",
    "        horizon=horizon,\n",
    "        feature_names=feature_names,\n",
    "        best_iteration=bst.best_iteration if hasattr(bst, 'best_iteration') else n_estimators,\n",
    "        feature_importance=importance_dict\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03007bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# FORECASTING\n",
    "# =========================================\n",
    "def forecast_multi_horizon_xgb(\n",
    "    snapshots: dict[int, XGBSnapshot],\n",
    "    X_seg: np.ndarray,\n",
    "    price_seg: pd.Series,\n",
    "    horizons: list[int],\n",
    "    cost_bp: dict[int, float] | None = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate multi-horizon forecasts using trained XGBoost models.\n",
    "\n",
    "    XGBoost provides well-calibrated probabilities through its logistic objective.\n",
    "    \"\"\"\n",
    "    if cost_bp is None:\n",
    "        cost_bp = {h: DEFAULT_COST_BP.get(h, 8.0) for h in horizons}\n",
    "    cost_log = {h: bp_to_logret(float(cost_bp[h])) for h in horizons}\n",
    "\n",
    "    Tseg = X_seg.shape[0]\n",
    "    idx = price_seg.index\n",
    "    out = {}\n",
    "\n",
    "    for h in horizons:\n",
    "        if h not in snapshots:\n",
    "            print(f\"Warning: No model for horizon {h}, skipping\")\n",
    "            continue\n",
    "\n",
    "        snap = snapshots[h]\n",
    "        out_h = pd.DataFrame(index=idx[:-h] if h < Tseg else idx[:0])\n",
    "        T_h = Tseg - h\n",
    "\n",
    "        if T_h <= 0:\n",
    "            out[h] = out_h\n",
    "            continue\n",
    "\n",
    "        # Scale features\n",
    "        X_scaled = snap.scaler.transform(X_seg[:T_h])\n",
    "\n",
    "        # Create DMatrix\n",
    "        dtest = xgb.DMatrix(X_scaled, feature_names=snap.feature_names)\n",
    "\n",
    "        # Get probabilities\n",
    "        p_edge = snap.booster.predict(dtest)\n",
    "\n",
    "        # Expected return estimation\n",
    "        mu = p_edge * (cost_log[h] + 0.002) + (1 - p_edge) * (-cost_log[h] - 0.001)\n",
    "\n",
    "        # Uncertainty estimate (based on probability)\n",
    "        std_h = np.sqrt(p_edge * (1 - p_edge)) * 0.04\n",
    "\n",
    "        # Quantiles\n",
    "        q10 = mu - 1.28 * std_h\n",
    "        q50 = mu\n",
    "        q90 = mu + 1.28 * std_h\n",
    "\n",
    "        # Populate DataFrame\n",
    "        p_now = price_seg.iloc[:T_h].values\n",
    "\n",
    "        out_h['mu'] = mu\n",
    "        out_h['std'] = std_h\n",
    "        out_h['p_edge_raw'] = p_edge\n",
    "        out_h['ret_q10'] = q10\n",
    "        out_h['ret_q50'] = q50\n",
    "        out_h['ret_q90'] = q90\n",
    "        out_h['price_pred'] = p_now * np.exp(mu)\n",
    "        out_h['price_q10'] = p_now * np.exp(q10)\n",
    "        out_h['price_q50'] = p_now * np.exp(q50)\n",
    "        out_h['price_q90'] = p_now * np.exp(q90)\n",
    "\n",
    "        out[h] = out_h\n",
    "\n",
    "    return out, cost_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fea6390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# CALIBRATION\n",
    "# =========================================\n",
    "@dataclass\n",
    "class ProbCalibrator:\n",
    "    \"\"\"Probability calibrator using isotonic regression.\"\"\"\n",
    "    method: str\n",
    "    iso: IsotonicRegression | None = None\n",
    "\n",
    "\n",
    "def fit_prob_calibrator_isotonic(p_raw: np.ndarray, y: np.ndarray,\n",
    "                                 min_points: int = 30) -> ProbCalibrator:\n",
    "    \"\"\"Fit isotonic regression p_raw -> y.\"\"\"\n",
    "    p_raw = np.asarray(p_raw, float)\n",
    "    y = np.asarray(y, float)\n",
    "    m = np.isfinite(p_raw) & np.isfinite(y)\n",
    "    p, t = p_raw[m], y[m]\n",
    "    if p.size < min_points or np.unique(p).size < 3:\n",
    "        return ProbCalibrator(method=\"identity\", iso=None)\n",
    "    iso = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "    iso.fit(p, t)\n",
    "    return ProbCalibrator(method=\"isotonic\", iso=iso)\n",
    "\n",
    "\n",
    "def apply_prob_calibrator(cal: ProbCalibrator, p_raw: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply probability calibrator.\"\"\"\n",
    "    p_raw = np.asarray(p_raw, float)\n",
    "    if cal.method == \"isotonic\":\n",
    "        return cal.iso.predict(p_raw)\n",
    "    return p_raw\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class IntervalCalibrator:\n",
    "    \"\"\"Conformal prediction interval calibrator.\"\"\"\n",
    "    method: str\n",
    "    q_alpha: float\n",
    "    alpha: float\n",
    "\n",
    "\n",
    "def fit_conformal_interval(residuals: np.ndarray, alpha: float = 0.2) -> IntervalCalibrator:\n",
    "    \"\"\"Fit conformal prediction intervals.\"\"\"\n",
    "    resid = np.asarray(residuals, float)\n",
    "    resid = resid[np.isfinite(resid)]\n",
    "    q = float(np.quantile(np.abs(resid), 1 - alpha)) if resid.size > 0 else 0.0\n",
    "    return IntervalCalibrator(method=\"conformal_abs\", q_alpha=q, alpha=alpha)\n",
    "\n",
    "\n",
    "def apply_conformal_interval(cal: IntervalCalibrator, mu: np.ndarray):\n",
    "    \"\"\"Apply conformal prediction intervals.\"\"\"\n",
    "    mu = np.asarray(mu, float)\n",
    "    return mu - cal.q_alpha, mu + cal.q_alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024686c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# FEATURE IMPORTANCE ANALYSIS\n",
    "# =========================================\n",
    "def analyze_feature_importance(snapshots: dict[int, XGBSnapshot]):\n",
    "    \"\"\"\n",
    "    Analyze and print feature importance from XGBoost models.\n",
    "\n",
    "    XGBoost provides multiple importance types:\n",
    "    - 'gain': Average gain across all splits using the feature\n",
    "    - 'weight': Number of times feature is used in splits\n",
    "    - 'cover': Average coverage (samples affected) by splits using feature\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FEATURE IMPORTANCE ANALYSIS (XGBoost)\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nNote: 'Gain' measures average improvement in loss when splitting on feature.\")\n",
    "    print(\"Higher gain = more important for predictions.\\n\")\n",
    "\n",
    "    for h, snap in snapshots.items():\n",
    "        if snap.feature_importance is None or not snap.feature_importance:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nHorizon {h} (best iteration: {snap.best_iteration}):\")\n",
    "\n",
    "        # Sort by gain (importance)\n",
    "        sorted_features = sorted(snap.feature_importance.items(),\n",
    "                               key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Normalize to percentages\n",
    "        total_gain = sum(gain for _, gain in sorted_features)\n",
    "\n",
    "        print(\"  Top Features by Gain:\")\n",
    "        for i, (feat, gain) in enumerate(sorted_features[:10]):\n",
    "            pct = (gain / total_gain * 100) if total_gain > 0 else 0\n",
    "            print(f\"    {i+1}. {feat:15s}: {gain:8.2f} ({pct:5.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5173733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# MAIN TRAINING PIPELINE\n",
    "# =========================================\n",
    "def run_xgb_for_symbol(symbol: str, path: Path,\n",
    "                       horizons: list[int] = HORIZONS,\n",
    "                       n_folds: int = 3,\n",
    "                       embargo: int = 24,\n",
    "                       n_estimators: int = 100,\n",
    "                       max_depth: int = 6,\n",
    "                       learning_rate: float = 0.1,\n",
    "                       early_stopping: bool = True,\n",
    "                       save_plots: bool = True):\n",
    "    \"\"\"\n",
    "    Train and evaluate XGBoost models for one symbol.\n",
    "\n",
    "    Args:\n",
    "        symbol: Asset symbol\n",
    "        path: Path to CSV file\n",
    "        horizons: Forecast horizons in bars\n",
    "        n_folds: Number of walk-forward folds\n",
    "        embargo: Embargo period between folds\n",
    "        n_estimators: Number of boosting rounds\n",
    "        max_depth: Maximum tree depth (3-10 typical)\n",
    "        learning_rate: Step size shrinkage (0.01-0.3 typical)\n",
    "        early_stopping: Use validation set for early stopping\n",
    "        save_plots: If True, save confusion matrix and ROC curves\n",
    "\n",
    "    Returns:\n",
    "        results: dict[horizon] -> dict with 'val', 'test', 'diag', 'metrics'\n",
    "    \"\"\"\n",
    "    if not XGBOOST_AVAILABLE:\n",
    "        raise ImportError(\"XGBoost not installed. Run: pip install xgboost\")\n",
    "\n",
    "    # Load data\n",
    "    df_raw = pd.read_csv(path)\n",
    "    close_col = _find_close_column(df_raw)\n",
    "    close = pd.Series(df_raw[close_col].astype(float).values,\n",
    "                      index=pd.RangeIndex(len(df_raw)), name=\"close\")\n",
    "\n",
    "    feat_df, X = make_feature_table(close)\n",
    "    price = feat_df[\"price\"]\n",
    "    n = len(price)\n",
    "\n",
    "    # Get feature names\n",
    "    feature_names = [c for c in feat_df.columns if c != \"price\"]\n",
    "\n",
    "    folds = purged_walkforward_slices(n, n_folds=n_folds, embargo=embargo)\n",
    "\n",
    "    results = {h: {\"val\": [], \"test\": [], \"diag\": [], \"metrics\": []} for h in horizons}\n",
    "\n",
    "    # Create plots directory\n",
    "    if save_plots:\n",
    "        plots_dir = DATA_DIR / \"evaluation_plots\" / symbol\n",
    "        plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training XGBoost for {symbol}\")\n",
    "    print(f\"Horizons: {horizons}\")\n",
    "    print(f\"Folds: {n_folds}\")\n",
    "    print(f\"Params: n_estimators={n_estimators}, max_depth={max_depth}, lr={learning_rate}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    for fold_idx, ((s0,e0), (s1,e1), (s2,e2)) in enumerate(folds):\n",
    "        print(f\"Fold {fold_idx + 1}/{len(folds)}: Train[{s0}:{e0}] Val[{s1}:{e1}] Test[{s2}:{e2}]\")\n",
    "\n",
    "        # Train one XGBoost per horizon\n",
    "        snapshots = {}\n",
    "\n",
    "        for h in horizons:\n",
    "            print(f\"  Training h={h}...\", end=\" \")\n",
    "\n",
    "            # Create labels for this horizon\n",
    "            ret_train = cumulative_log_returns(price.iloc[s0:e0], h)\n",
    "            ret_val = cumulative_log_returns(price.iloc[s1:e1], h)\n",
    "\n",
    "            # Align features and labels\n",
    "            n_train = min(len(X[s0:e0]), len(ret_train))\n",
    "            X_train_aligned = X[s0:s0+n_train]\n",
    "            ret_train_aligned = ret_train.iloc[:n_train]\n",
    "\n",
    "            if len(X_train_aligned) < 50:\n",
    "                print(\"SKIP (insufficient data)\")\n",
    "                continue\n",
    "\n",
    "            # Binary classification\n",
    "            y_train = (ret_train_aligned.values > bp_to_logret(DEFAULT_COST_BP[h])).astype(int)\n",
    "\n",
    "            # Validation set for early stopping\n",
    "            X_val_use, y_val_use = None, None\n",
    "            if early_stopping:\n",
    "                n_val = min(len(X[s1:e1]), len(ret_val))\n",
    "                X_val_use = X[s1:s1+n_val]\n",
    "                y_val_use = (ret_val.iloc[:n_val].values > bp_to_logret(DEFAULT_COST_BP[h])).astype(int)\n",
    "\n",
    "            # Check class balance\n",
    "            pos_frac = y_train.mean()\n",
    "            if pos_frac < 0.1 or pos_frac > 0.9:\n",
    "                print(f\"WARN (imbalanced: {pos_frac:.2%} positive)\", end=\" \")\n",
    "\n",
    "            snap = fit_xgboost_classifier(\n",
    "                X_train_aligned, y_train,\n",
    "                X_val=X_val_use, y_val=y_val_use,\n",
    "                horizon=h,\n",
    "                feature_names=feature_names,\n",
    "                random_state=123 + fold_idx,\n",
    "                n_estimators=n_estimators,\n",
    "                max_depth=max_depth,\n",
    "                learning_rate=learning_rate,\n",
    "                early_stopping_rounds=10 if early_stopping else None\n",
    "            )\n",
    "\n",
    "            snapshots[h] = snap\n",
    "            print(f\"✓ (best_iter={snap.best_iteration})\")\n",
    "\n",
    "        if not snapshots:\n",
    "            print(\"  No models trained, skipping fold\")\n",
    "            continue\n",
    "\n",
    "        # Feature importance analysis (first fold only)\n",
    "        if fold_idx == 0:\n",
    "            analyze_feature_importance(snapshots)\n",
    "\n",
    "        # Forecast on validation and test\n",
    "        print(\"  Forecasting validation...\", end=\" \")\n",
    "        out_val_raw, cost_log = forecast_multi_horizon_xgb(\n",
    "            snapshots=snapshots,\n",
    "            X_seg=X[s1:e1],\n",
    "            price_seg=price.iloc[s1:e1],\n",
    "            horizons=horizons\n",
    "        )\n",
    "        print(\"✓\")\n",
    "\n",
    "        print(\"  Forecasting test...\", end=\" \")\n",
    "        out_test_raw, _ = forecast_multi_horizon_xgb(\n",
    "            snapshots=snapshots,\n",
    "            X_seg=X[s2:e2],\n",
    "            price_seg=price.iloc[s2:e2],\n",
    "            horizons=horizons\n",
    "        )\n",
    "        print(\"✓\")\n",
    "\n",
    "        # Calibration and evaluation\n",
    "        for h in horizons:\n",
    "            if h not in out_val_raw or h not in out_test_raw:\n",
    "                continue\n",
    "\n",
    "            ret_val = cumulative_log_returns(price.iloc[s1:e1], h)\n",
    "            idx_common = out_val_raw[h].index.intersection(ret_val.index)\n",
    "\n",
    "            if len(idx_common) == 0:\n",
    "                continue\n",
    "\n",
    "            dfV = out_val_raw[h].loc[idx_common].copy()\n",
    "            maskV = np.isfinite(dfV[\"p_edge_raw\"].values) & np.isfinite(dfV[\"mu\"].values)\n",
    "            dfV = dfV[maskV]\n",
    "\n",
    "            if len(dfV) < 20:\n",
    "                continue\n",
    "\n",
    "            ret_val_aligned = ret_val.loc[dfV.index]\n",
    "            y_val = (ret_val_aligned.values > cost_log[h]).astype(int)\n",
    "            p_raw_val = dfV[\"p_edge_raw\"].values\n",
    "            mu_val = dfV[\"mu\"].values\n",
    "\n",
    "            # Fit calibrators\n",
    "            cal_prob = fit_prob_calibrator_isotonic(p_raw_val, y_val, min_points=20)\n",
    "            resid_val = ret_val_aligned.values - mu_val\n",
    "            cal_pi = fit_conformal_interval(resid_val, alpha=0.2)\n",
    "\n",
    "            # Apply to test\n",
    "            ret_test = cumulative_log_returns(price.iloc[s2:e2], h)\n",
    "            idx_test_common = out_test_raw[h].index.intersection(ret_test.index)\n",
    "            dfT = out_test_raw[h].loc[idx_test_common].copy()\n",
    "\n",
    "            maskT = np.isfinite(dfT[\"p_edge_raw\"].values) & np.isfinite(dfT[\"mu\"].values)\n",
    "            dfT = dfT[maskT]\n",
    "\n",
    "            if len(dfT) == 0:\n",
    "                continue\n",
    "\n",
    "            dfT[\"p_edge\"] = apply_prob_calibrator(cal_prob, dfT[\"p_edge_raw\"].values)\n",
    "            mu_test = dfT[\"mu\"].values\n",
    "            lo, hi = apply_conformal_interval(cal_pi, mu_test)\n",
    "            dfT[\"ret_lo\"] = lo\n",
    "            dfT[\"ret_hi\"] = hi\n",
    "\n",
    "            p_now = price.loc[dfT.index].values\n",
    "            dfT[\"price_lo\"] = p_now * np.exp(lo)\n",
    "            dfT[\"price_hi\"] = p_now * np.exp(hi)\n",
    "\n",
    "            dfT[\"edge\"] = dfT[\"mu\"] - cost_log[h]\n",
    "            dfT[\"risk_edge\"] = (dfT[\"mu\"] - cost_log[h]) / (dfT[\"std\"] + 1e-12)\n",
    "\n",
    "            results[h][\"test\"].append(dfT)\n",
    "\n",
    "            # Compute classification metrics\n",
    "            ret_test_aligned = ret_test.loc[dfT.index]\n",
    "            y_test_true = (ret_test_aligned.values > cost_log[h]).astype(int)\n",
    "            y_test_pred = (dfT[\"p_edge\"].values > 0.5).astype(int)\n",
    "            y_test_prob = dfT[\"p_edge\"].values\n",
    "\n",
    "            test_metrics = compute_classification_metrics(\n",
    "                y_test_true, y_test_pred, y_test_prob\n",
    "            )\n",
    "\n",
    "            # Print detailed report\n",
    "            print_classification_report(test_metrics, h, \"test\")\n",
    "\n",
    "            # Save plots (only for last fold)\n",
    "            if save_plots and fold_idx == len(folds) - 1:\n",
    "                print(f\"\\n  Generating evaluation plots for horizon {h}...\")\n",
    "\n",
    "                cm_path = plots_dir / f\"confusion_matrix_h{h}.png\"\n",
    "                plot_confusion_matrix(test_metrics['confusion_matrix'], h, cm_path)\n",
    "\n",
    "                if test_metrics.get('roc_auc') is not None:\n",
    "                    roc_path = plots_dir / f\"roc_curve_h{h}.png\"\n",
    "                    plot_roc_curve(y_test_true, y_test_prob, h, roc_path)\n",
    "\n",
    "                    pr_path = plots_dir / f\"precision_recall_h{h}.png\"\n",
    "                    plot_precision_recall_curve(y_test_true, y_test_prob, h, pr_path)\n",
    "\n",
    "            results[h][\"metrics\"].append(test_metrics)\n",
    "\n",
    "            # Calibration diagnostics\n",
    "            if cal_prob.method == \"isotonic\":\n",
    "                p_cal_val = apply_prob_calibrator(cal_prob, p_raw_val)\n",
    "                brier = brier_score(y_val, p_cal_val)\n",
    "                ece = expected_calibration_error(y_val, p_cal_val)\n",
    "            else:\n",
    "                brier = brier_score(y_val, p_raw_val)\n",
    "                ece = expected_calibration_error(y_val, p_raw_val)\n",
    "\n",
    "            coverage = float(np.mean((resid_val >= -cal_pi.q_alpha) & (resid_val <= cal_pi.q_alpha)))\n",
    "\n",
    "            diag = {\n",
    "                \"h\": h,\n",
    "                \"brier_val\": float(brier),\n",
    "                \"ece_val\": float(ece),\n",
    "                \"pi_coverage_val\": coverage\n",
    "            }\n",
    "            results[h][\"diag\"].append(diag)\n",
    "\n",
    "            # Store validation\n",
    "            dfV[\"p_edge\"] = apply_prob_calibrator(cal_prob, dfV[\"p_edge_raw\"].values)\n",
    "            loV, hiV = apply_conformal_interval(cal_pi, mu_val)\n",
    "            dfV[\"ret_lo\"], dfV[\"ret_hi\"] = loV, hiV\n",
    "            results[h][\"val\"].append(dfV)\n",
    "\n",
    "    # Concatenate folds\n",
    "    for h in horizons:\n",
    "        for split in (\"val\", \"test\"):\n",
    "            if results[h][split]:\n",
    "                results[h][split] = pd.concat(results[h][split]).sort_index()\n",
    "            else:\n",
    "                results[h][split] = pd.DataFrame()\n",
    "\n",
    "    print(f\"\\nCompleted {symbol}\\n\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11634305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# JSON EXPORT\n",
    "# =========================================\n",
    "def build_json_records(all_outputs: dict,\n",
    "                       model_version: str = MODEL_VERSION,\n",
    "                       calibration_version: str = CALIBRATION_VERSION,\n",
    "                       horizons: list[int] = HORIZONS):\n",
    "    \"\"\"Build JSONL records for trading agent.\"\"\"\n",
    "    records = []\n",
    "    for sym, res in all_outputs.items():\n",
    "        for h in horizons:\n",
    "            df = res[h][\"test\"]\n",
    "            if isinstance(df, list) or isinstance(df, tuple):\n",
    "                df = pd.concat(df).sort_index()\n",
    "            for t, row in df.iterrows():\n",
    "                rec = {\n",
    "                    \"timestamp_index\": int(t),\n",
    "                    \"symbol\": sym,\n",
    "                    \"horizon_bars\": int(h),\n",
    "                    \"model_version\": model_version,\n",
    "                    \"calibration_version\": calibration_version,\n",
    "                    \"signals\": {\n",
    "                        \"expected_return\": float(row[\"mu\"]),\n",
    "                        \"stdev_return\": float(row[\"std\"]),\n",
    "                        \"p_edge_gt_cost\": float(row[\"p_edge\"]),\n",
    "                        \"predicted_price\": float(row[\"price_pred\"]),\n",
    "                        \"price_PI\": {\n",
    "                            \"p10\": float(row[\"price_q10\"]),\n",
    "                            \"p50\": float(row[\"price_q50\"]),\n",
    "                            \"p90\": float(row[\"price_q90\"])\n",
    "                        }\n",
    "                    },\n",
    "                    \"policy_suggestions\": {\n",
    "                        \"gate_threshold_p\": TAU_P,\n",
    "                        \"gate_threshold_edge\": TAU_MU,\n",
    "                        \"suggested_action\": \"buy\" if (row[\"p_edge\"]>=TAU_P and row[\"edge\"]>=TAU_MU and row[\"mu\"]>0)\n",
    "                                            else (\"sell\" if (row[\"p_edge\"]>=TAU_P and row[\"edge\"]>=TAU_MU and row[\"mu\"]<0)\n",
    "                                                  else \"hold\")\n",
    "                    }\n",
    "                }\n",
    "                records.append(rec)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d245b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training XGBoost for BTC\n",
      "Horizons: [1, 3, 6]\n",
      "Folds: 3\n",
      "Params: n_estimators=100, max_depth=6, lr=0.1\n",
      "============================================================\n",
      "\n",
      "Fold 1/3: Train[0:1749] Val[1773:3522] Test[3546:5295]\n",
      "  Training h=1... ✓ (best_iter=11)\n",
      "  Training h=3... ✓ (best_iter=5)\n",
      "  Training h=6... ✓ (best_iter=0)\n",
      "\n",
      "============================================================\n",
      "FEATURE IMPORTANCE ANALYSIS (XGBoost)\n",
      "============================================================\n",
      "\n",
      "Note: 'Gain' measures average improvement in loss when splitting on feature.\n",
      "Higher gain = more important for predictions.\n",
      "\n",
      "\n",
      "Horizon 1 (best iteration: 11):\n",
      "  Top Features by Gain:\n",
      "    1. ret_3          :     3.48 ( 17.3%)\n",
      "    2. ret_1          :     3.45 ( 17.2%)\n",
      "    3. ret_6          :     3.37 ( 16.8%)\n",
      "    4. vol_6          :     3.31 ( 16.5%)\n",
      "    5. ma_ratio       :     3.26 ( 16.2%)\n",
      "    6. vol_12         :     3.23 ( 16.1%)\n",
      "\n",
      "Horizon 3 (best iteration: 5):\n",
      "  Top Features by Gain:\n",
      "    1. vol_12         :     4.27 ( 18.0%)\n",
      "    2. ret_3          :     4.26 ( 18.0%)\n",
      "    3. ma_ratio       :     4.17 ( 17.6%)\n",
      "    4. ret_6          :     3.89 ( 16.4%)\n",
      "    5. vol_6          :     3.66 ( 15.5%)\n",
      "    6. ret_1          :     3.42 ( 14.5%)\n",
      "\n",
      "Horizon 6 (best iteration: 0):\n",
      "  Top Features by Gain:\n",
      "    1. vol_12         :     5.86 ( 20.2%)\n",
      "    2. ma_ratio       :     5.36 ( 18.5%)\n",
      "    3. vol_6          :     5.20 ( 17.9%)\n",
      "    4. ret_6          :     4.90 ( 16.9%)\n",
      "    5. ret_3          :     4.15 ( 14.3%)\n",
      "    6. ret_1          :     3.50 ( 12.1%)\n",
      "  Forecasting validation... ✓\n",
      "  Forecasting test... ✓\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 1 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           925                  28\n",
      "Actual Positive           762                  33\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5481\n",
      "  Balanced Accuracy:  0.5061\n",
      "  Precision:          0.5410\n",
      "  Recall (TPR):       0.0415\n",
      "  Specificity (TNR):  0.9706\n",
      "  F1 Score:           0.0771\n",
      "  ROC-AUC:            0.5329\n",
      "  Average Precision:  0.4864\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     33\n",
      "  True Negatives:     925\n",
      "  False Positives:    28\n",
      "  False Negatives:    762\n",
      "  Total Samples:      1748\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 3 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           934                   0\n",
      "Actual Positive           812                   0\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5349\n",
      "  Balanced Accuracy:  0.5000\n",
      "  Precision:          0.0000\n",
      "  Recall (TPR):       0.0000\n",
      "  Specificity (TNR):  1.0000\n",
      "  F1 Score:           0.0000\n",
      "  ROC-AUC:            0.4961\n",
      "  Average Precision:  0.4625\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     0\n",
      "  True Negatives:     934\n",
      "  False Positives:    0\n",
      "  False Negatives:    812\n",
      "  Total Samples:      1746\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 6 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           880                   8\n",
      "Actual Positive           849                   6\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5083\n",
      "  Balanced Accuracy:  0.4990\n",
      "  Precision:          0.4286\n",
      "  Recall (TPR):       0.0070\n",
      "  Specificity (TNR):  0.9910\n",
      "  F1 Score:           0.0138\n",
      "  ROC-AUC:            0.4912\n",
      "  Average Precision:  0.4859\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     6\n",
      "  True Negatives:     880\n",
      "  False Positives:    8\n",
      "  False Negatives:    849\n",
      "  Total Samples:      1743\n",
      "Fold 2/3: Train[0:3498] Val[3522:5271] Test[5295:7044]\n",
      "  Training h=1... ✓ (best_iter=14)\n",
      "  Training h=3... ✓ (best_iter=10)\n",
      "  Training h=6... ✓ (best_iter=5)\n",
      "  Forecasting validation... ✓\n",
      "  Forecasting test... ✓\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 1 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           741                 180\n",
      "Actual Positive           638                 189\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5320\n",
      "  Balanced Accuracy:  0.5165\n",
      "  Precision:          0.5122\n",
      "  Recall (TPR):       0.2285\n",
      "  Specificity (TNR):  0.8046\n",
      "  F1 Score:           0.3161\n",
      "  ROC-AUC:            0.5297\n",
      "  Average Precision:  0.4920\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     189\n",
      "  True Negatives:     741\n",
      "  False Positives:    180\n",
      "  False Negatives:    638\n",
      "  Total Samples:      1748\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 3 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           407                 466\n",
      "Actual Positive           364                 509\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5246\n",
      "  Balanced Accuracy:  0.5246\n",
      "  Precision:          0.5221\n",
      "  Recall (TPR):       0.5830\n",
      "  Specificity (TNR):  0.4662\n",
      "  F1 Score:           0.5509\n",
      "  ROC-AUC:            0.5261\n",
      "  Average Precision:  0.5177\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     509\n",
      "  True Negatives:     407\n",
      "  False Positives:    466\n",
      "  False Negatives:    364\n",
      "  Total Samples:      1746\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 6 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           599                 260\n",
      "Actual Positive           599                 285\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5072\n",
      "  Balanced Accuracy:  0.5099\n",
      "  Precision:          0.5229\n",
      "  Recall (TPR):       0.3224\n",
      "  Specificity (TNR):  0.6973\n",
      "  F1 Score:           0.3989\n",
      "  ROC-AUC:            0.5218\n",
      "  Average Precision:  0.5308\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     285\n",
      "  True Negatives:     599\n",
      "  False Positives:    260\n",
      "  False Negatives:    599\n",
      "  Total Samples:      1743\n",
      "Fold 3/3: Train[0:5247] Val[5271:7020] Test[7044:8747]\n",
      "  Training h=1... ✓ (best_iter=8)\n",
      "  Training h=3... ✓ (best_iter=9)\n",
      "  Training h=6... ✓ (best_iter=2)\n",
      "  Forecasting validation... ✓\n",
      "  Forecasting test... ✓\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 1 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           671                 282\n",
      "Actual Positive           489                 260\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5470\n",
      "  Balanced Accuracy:  0.5256\n",
      "  Precision:          0.4797\n",
      "  Recall (TPR):       0.3471\n",
      "  Specificity (TNR):  0.7041\n",
      "  F1 Score:           0.4028\n",
      "  ROC-AUC:            0.5318\n",
      "  Average Precision:  0.4610\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     260\n",
      "  True Negatives:     671\n",
      "  False Positives:    282\n",
      "  False Negatives:    489\n",
      "  Total Samples:      1702\n",
      "\n",
      "  Generating evaluation plots for horizon 1...\n",
      "  Saved confusion matrix to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/BTC/confusion_matrix_h1.png\n",
      "  Saved ROC curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/BTC/roc_curve_h1.png\n",
      "  Saved PR curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/BTC/precision_recall_h1.png\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 3 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           596                 300\n",
      "Actual Positive           548                 256\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5012\n",
      "  Balanced Accuracy:  0.4918\n",
      "  Precision:          0.4604\n",
      "  Recall (TPR):       0.3184\n",
      "  Specificity (TNR):  0.6652\n",
      "  F1 Score:           0.3765\n",
      "  ROC-AUC:            0.4882\n",
      "  Average Precision:  0.4751\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     256\n",
      "  True Negatives:     596\n",
      "  False Positives:    300\n",
      "  False Negatives:    548\n",
      "  Total Samples:      1700\n",
      "\n",
      "  Generating evaluation plots for horizon 3...\n",
      "  Saved confusion matrix to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/BTC/confusion_matrix_h3.png\n",
      "  Saved ROC curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/BTC/roc_curve_h3.png\n",
      "  Saved PR curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/BTC/precision_recall_h3.png\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 6 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           786                  94\n",
      "Actual Positive           704                 113\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5298\n",
      "  Balanced Accuracy:  0.5157\n",
      "  Precision:          0.5459\n",
      "  Recall (TPR):       0.1383\n",
      "  Specificity (TNR):  0.8932\n",
      "  F1 Score:           0.2207\n",
      "  ROC-AUC:            0.5262\n",
      "  Average Precision:  0.5007\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     113\n",
      "  True Negatives:     786\n",
      "  False Positives:    94\n",
      "  False Negatives:    704\n",
      "  Total Samples:      1697\n",
      "\n",
      "  Generating evaluation plots for horizon 6...\n",
      "  Saved confusion matrix to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/BTC/confusion_matrix_h6.png\n",
      "  Saved ROC curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/BTC/roc_curve_h6.png\n",
      "  Saved PR curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/BTC/precision_recall_h6.png\n",
      "\n",
      "Completed BTC\n",
      "\n",
      "\n",
      "============================================================\n",
      "SUMMARY FOR BTC\n",
      "============================================================\n",
      "\n",
      "Horizon 1:\n",
      "  Test samples:      5198\n",
      "  Accuracy:          0.5424\n",
      "  Balanced Acc:      0.5161\n",
      "  Precision:         0.5110\n",
      "  Recall:            0.2057\n",
      "  F1 Score:          0.2653\n",
      "  ROC-AUC:           0.5315\n",
      "  Brier Score:       0.2446\n",
      "  ECE:               0.0000\n",
      "\n",
      "Horizon 3:\n",
      "  Test samples:      5192\n",
      "  Accuracy:          0.5202\n",
      "  Balanced Acc:      0.5055\n",
      "  Precision:         0.3275\n",
      "  Recall:            0.3005\n",
      "  F1 Score:          0.3091\n",
      "  ROC-AUC:           0.5035\n",
      "  Brier Score:       0.2452\n",
      "  ECE:               0.0000\n",
      "\n",
      "Horizon 6:\n",
      "  Test samples:      5183\n",
      "  Accuracy:          0.5151\n",
      "  Balanced Acc:      0.5082\n",
      "  Precision:         0.4991\n",
      "  Recall:            0.1559\n",
      "  F1 Score:          0.2111\n",
      "  ROC-AUC:           0.5130\n",
      "  Brier Score:       0.2465\n",
      "  ECE:               0.0000\n",
      "\n",
      "============================================================\n",
      "Training XGBoost for ETH\n",
      "Horizons: [1, 3, 6]\n",
      "Folds: 3\n",
      "Params: n_estimators=100, max_depth=6, lr=0.1\n",
      "============================================================\n",
      "\n",
      "Fold 1/3: Train[0:1749] Val[1773:3522] Test[3546:5295]\n",
      "  Training h=1... ✓ (best_iter=5)\n",
      "  Training h=3... ✓ (best_iter=0)\n",
      "  Training h=6... ✓ (best_iter=5)\n",
      "\n",
      "============================================================\n",
      "FEATURE IMPORTANCE ANALYSIS (XGBoost)\n",
      "============================================================\n",
      "\n",
      "Note: 'Gain' measures average improvement in loss when splitting on feature.\n",
      "Higher gain = more important for predictions.\n",
      "\n",
      "\n",
      "Horizon 1 (best iteration: 5):\n",
      "  Top Features by Gain:\n",
      "    1. ret_1          :     3.67 ( 17.9%)\n",
      "    2. ret_6          :     3.56 ( 17.4%)\n",
      "    3. ret_3          :     3.53 ( 17.2%)\n",
      "    4. ma_ratio       :     3.46 ( 16.9%)\n",
      "    5. vol_12         :     3.41 ( 16.7%)\n",
      "    6. vol_6          :     2.84 ( 13.9%)\n",
      "\n",
      "Horizon 3 (best iteration: 0):\n",
      "  Top Features by Gain:\n",
      "    1. vol_12         :     4.19 ( 18.1%)\n",
      "    2. ma_ratio       :     3.96 ( 17.2%)\n",
      "    3. vol_6          :     3.94 ( 17.1%)\n",
      "    4. ret_3          :     3.79 ( 16.4%)\n",
      "    5. ret_6          :     3.63 ( 15.7%)\n",
      "    6. ret_1          :     3.56 ( 15.4%)\n",
      "\n",
      "Horizon 6 (best iteration: 5):\n",
      "  Top Features by Gain:\n",
      "    1. ma_ratio       :     4.43 ( 18.0%)\n",
      "    2. vol_12         :     4.41 ( 17.9%)\n",
      "    3. ret_6          :     4.35 ( 17.7%)\n",
      "    4. vol_6          :     4.09 ( 16.6%)\n",
      "    5. ret_3          :     3.96 ( 16.1%)\n",
      "    6. ret_1          :     3.37 ( 13.7%)\n",
      "  Forecasting validation... ✓\n",
      "  Forecasting test... ✓\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 1 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           931                  37\n",
      "Actual Positive           745                  35\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5526\n",
      "  Balanced Accuracy:  0.5033\n",
      "  Precision:          0.4861\n",
      "  Recall (TPR):       0.0449\n",
      "  Specificity (TNR):  0.9618\n",
      "  F1 Score:           0.0822\n",
      "  ROC-AUC:            0.4977\n",
      "  Average Precision:  0.4470\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     35\n",
      "  True Negatives:     931\n",
      "  False Positives:    37\n",
      "  False Negatives:    745\n",
      "  Total Samples:      1748\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 3 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           927                  15\n",
      "Actual Positive           791                  13\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5384\n",
      "  Balanced Accuracy:  0.5001\n",
      "  Precision:          0.4643\n",
      "  Recall (TPR):       0.0162\n",
      "  Specificity (TNR):  0.9841\n",
      "  F1 Score:           0.0312\n",
      "  ROC-AUC:            0.4882\n",
      "  Average Precision:  0.4570\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     13\n",
      "  True Negatives:     927\n",
      "  False Positives:    15\n",
      "  False Negatives:    791\n",
      "  Total Samples:      1746\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 6 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           331                 562\n",
      "Actual Positive           293                 557\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5095\n",
      "  Balanced Accuracy:  0.5130\n",
      "  Precision:          0.4978\n",
      "  Recall (TPR):       0.6553\n",
      "  Specificity (TNR):  0.3707\n",
      "  F1 Score:           0.5658\n",
      "  ROC-AUC:            0.5010\n",
      "  Average Precision:  0.4884\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     557\n",
      "  True Negatives:     331\n",
      "  False Positives:    562\n",
      "  False Negatives:    293\n",
      "  Total Samples:      1743\n",
      "Fold 2/3: Train[0:3498] Val[3522:5271] Test[5295:7044]\n",
      "  Training h=1... ✓ (best_iter=12)\n",
      "  Training h=3... ✓ (best_iter=11)\n",
      "  Training h=6... ✓ (best_iter=0)\n",
      "  Forecasting validation... ✓\n",
      "  Forecasting test... ✓\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 1 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           827                  92\n",
      "Actual Positive           732                  97\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5286\n",
      "  Balanced Accuracy:  0.5084\n",
      "  Precision:          0.5132\n",
      "  Recall (TPR):       0.1170\n",
      "  Specificity (TNR):  0.8999\n",
      "  F1 Score:           0.1906\n",
      "  ROC-AUC:            0.5272\n",
      "  Average Precision:  0.4928\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     97\n",
      "  True Negatives:     827\n",
      "  False Positives:    92\n",
      "  False Negatives:    732\n",
      "  Total Samples:      1748\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 3 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           890                  18\n",
      "Actual Positive           818                  20\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5212\n",
      "  Balanced Accuracy:  0.5020\n",
      "  Precision:          0.5263\n",
      "  Recall (TPR):       0.0239\n",
      "  Specificity (TNR):  0.9802\n",
      "  F1 Score:           0.0457\n",
      "  ROC-AUC:            0.5273\n",
      "  Average Precision:  0.4977\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     20\n",
      "  True Negatives:     890\n",
      "  False Positives:    18\n",
      "  False Negatives:    818\n",
      "  Total Samples:      1746\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 6 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           699                 189\n",
      "Actual Positive           708                 147\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.4854\n",
      "  Balanced Accuracy:  0.4795\n",
      "  Precision:          0.4375\n",
      "  Recall (TPR):       0.1719\n",
      "  Specificity (TNR):  0.7872\n",
      "  F1 Score:           0.2469\n",
      "  ROC-AUC:            0.5040\n",
      "  Average Precision:  0.4888\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     147\n",
      "  True Negatives:     699\n",
      "  False Positives:    189\n",
      "  False Negatives:    708\n",
      "  Total Samples:      1743\n",
      "Fold 3/3: Train[0:5247] Val[5271:7020] Test[7044:8747]\n",
      "  Training h=1... ✓ (best_iter=1)\n",
      "  Training h=3... ✓ (best_iter=0)\n",
      "  Training h=6... ✓ (best_iter=0)\n",
      "  Forecasting validation... ✓\n",
      "  Forecasting test... ✓\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 1 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           766                 131\n",
      "Actual Positive           685                 120\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5206\n",
      "  Balanced Accuracy:  0.5015\n",
      "  Precision:          0.4781\n",
      "  Recall (TPR):       0.1491\n",
      "  Specificity (TNR):  0.8540\n",
      "  F1 Score:           0.2273\n",
      "  ROC-AUC:            0.5116\n",
      "  Average Precision:  0.4825\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     120\n",
      "  True Negatives:     766\n",
      "  False Positives:    131\n",
      "  False Negatives:    685\n",
      "  Total Samples:      1702\n",
      "\n",
      "  Generating evaluation plots for horizon 1...\n",
      "  Saved confusion matrix to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/ETH/confusion_matrix_h1.png\n",
      "  Saved ROC curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/ETH/roc_curve_h1.png\n",
      "  Saved PR curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/ETH/precision_recall_h1.png\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 3 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           757                  98\n",
      "Actual Positive           739                 106\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5076\n",
      "  Balanced Accuracy:  0.5054\n",
      "  Precision:          0.5196\n",
      "  Recall (TPR):       0.1254\n",
      "  Specificity (TNR):  0.8854\n",
      "  F1 Score:           0.2021\n",
      "  ROC-AUC:            0.5143\n",
      "  Average Precision:  0.5062\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     106\n",
      "  True Negatives:     757\n",
      "  False Positives:    98\n",
      "  False Negatives:    739\n",
      "  Total Samples:      1700\n",
      "\n",
      "  Generating evaluation plots for horizon 3...\n",
      "  Saved confusion matrix to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/ETH/confusion_matrix_h3.png\n",
      "  Saved ROC curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/ETH/roc_curve_h3.png\n",
      "  Saved PR curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/ETH/precision_recall_h3.png\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 6 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           442                 416\n",
      "Actual Positive           417                 422\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5091\n",
      "  Balanced Accuracy:  0.5091\n",
      "  Precision:          0.5036\n",
      "  Recall (TPR):       0.5030\n",
      "  Specificity (TNR):  0.5152\n",
      "  F1 Score:           0.5033\n",
      "  ROC-AUC:            0.5143\n",
      "  Average Precision:  0.5026\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     422\n",
      "  True Negatives:     442\n",
      "  False Positives:    416\n",
      "  False Negatives:    417\n",
      "  Total Samples:      1697\n",
      "\n",
      "  Generating evaluation plots for horizon 6...\n",
      "  Saved confusion matrix to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/ETH/confusion_matrix_h6.png\n",
      "  Saved ROC curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/ETH/roc_curve_h6.png\n",
      "  Saved PR curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/ETH/precision_recall_h6.png\n",
      "\n",
      "Completed ETH\n",
      "\n",
      "\n",
      "============================================================\n",
      "SUMMARY FOR ETH\n",
      "============================================================\n",
      "\n",
      "Horizon 1:\n",
      "  Test samples:      5198\n",
      "  Accuracy:          0.5339\n",
      "  Balanced Acc:      0.5044\n",
      "  Precision:         0.4925\n",
      "  Recall:            0.1036\n",
      "  F1 Score:          0.1667\n",
      "  ROC-AUC:           0.5122\n",
      "  Brier Score:       0.2454\n",
      "  ECE:               0.0000\n",
      "\n",
      "Horizon 3:\n",
      "  Test samples:      5192\n",
      "  Accuracy:          0.5224\n",
      "  Balanced Acc:      0.5025\n",
      "  Precision:         0.5034\n",
      "  Recall:            0.0552\n",
      "  F1 Score:          0.0930\n",
      "  ROC-AUC:           0.5100\n",
      "  Brier Score:       0.2471\n",
      "  ECE:               0.0000\n",
      "\n",
      "Horizon 6:\n",
      "  Test samples:      5183\n",
      "  Accuracy:          0.5013\n",
      "  Balanced Acc:      0.5005\n",
      "  Precision:         0.4796\n",
      "  Recall:            0.4434\n",
      "  F1 Score:          0.4386\n",
      "  ROC-AUC:           0.5064\n",
      "  Brier Score:       0.2483\n",
      "  ECE:               0.0000\n",
      "\n",
      "============================================================\n",
      "Training XGBoost for SOL\n",
      "Horizons: [1, 3, 6]\n",
      "Folds: 3\n",
      "Params: n_estimators=100, max_depth=6, lr=0.1\n",
      "============================================================\n",
      "\n",
      "Fold 1/3: Train[0:1749] Val[1773:3522] Test[3546:5295]\n",
      "  Training h=1... ✓ (best_iter=1)\n",
      "  Training h=3... ✓ (best_iter=3)\n",
      "  Training h=6... ✓ (best_iter=5)\n",
      "\n",
      "============================================================\n",
      "FEATURE IMPORTANCE ANALYSIS (XGBoost)\n",
      "============================================================\n",
      "\n",
      "Note: 'Gain' measures average improvement in loss when splitting on feature.\n",
      "Higher gain = more important for predictions.\n",
      "\n",
      "\n",
      "Horizon 1 (best iteration: 1):\n",
      "  Top Features by Gain:\n",
      "    1. vol_6          :     3.73 ( 18.7%)\n",
      "    2. ret_3          :     3.41 ( 17.1%)\n",
      "    3. ret_1          :     3.38 ( 16.9%)\n",
      "    4. ma_ratio       :     3.19 ( 16.0%)\n",
      "    5. vol_12         :     3.16 ( 15.8%)\n",
      "    6. ret_6          :     3.08 ( 15.4%)\n",
      "\n",
      "Horizon 3 (best iteration: 3):\n",
      "  Top Features by Gain:\n",
      "    1. ma_ratio       :     4.82 ( 20.6%)\n",
      "    2. vol_6          :     4.09 ( 17.5%)\n",
      "    3. ret_6          :     4.06 ( 17.4%)\n",
      "    4. vol_12         :     3.90 ( 16.7%)\n",
      "    5. ret_3          :     3.27 ( 14.0%)\n",
      "    6. ret_1          :     3.26 ( 13.9%)\n",
      "\n",
      "Horizon 6 (best iteration: 5):\n",
      "  Top Features by Gain:\n",
      "    1. ma_ratio       :     5.21 ( 20.7%)\n",
      "    2. vol_6          :     4.55 ( 18.0%)\n",
      "    3. vol_12         :     4.35 ( 17.2%)\n",
      "    4. ret_6          :     4.21 ( 16.7%)\n",
      "    5. ret_3          :     3.68 ( 14.6%)\n",
      "    6. ret_1          :     3.22 ( 12.8%)\n",
      "  Forecasting validation... ✓\n",
      "  Forecasting test... ✓\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 1 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           863                  11\n",
      "Actual Positive           852                  22\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5063\n",
      "  Balanced Accuracy:  0.5063\n",
      "  Precision:          0.6667\n",
      "  Recall (TPR):       0.0252\n",
      "  Specificity (TNR):  0.9874\n",
      "  F1 Score:           0.0485\n",
      "  ROC-AUC:            0.5079\n",
      "  Average Precision:  0.5087\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     22\n",
      "  True Negatives:     863\n",
      "  False Positives:    11\n",
      "  False Negatives:    852\n",
      "  Total Samples:      1748\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 3 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           811                  57\n",
      "Actual Positive           810                  68\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5034\n",
      "  Balanced Accuracy:  0.5059\n",
      "  Precision:          0.5440\n",
      "  Recall (TPR):       0.0774\n",
      "  Specificity (TNR):  0.9343\n",
      "  F1 Score:           0.1356\n",
      "  ROC-AUC:            0.5186\n",
      "  Average Precision:  0.5131\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     68\n",
      "  True Negatives:     811\n",
      "  False Positives:    57\n",
      "  False Negatives:    810\n",
      "  Total Samples:      1746\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 6 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           770                  87\n",
      "Actual Positive           769                 117\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5089\n",
      "  Balanced Accuracy:  0.5153\n",
      "  Precision:          0.5735\n",
      "  Recall (TPR):       0.1321\n",
      "  Specificity (TNR):  0.8985\n",
      "  F1 Score:           0.2147\n",
      "  ROC-AUC:            0.5193\n",
      "  Average Precision:  0.5319\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     117\n",
      "  True Negatives:     770\n",
      "  False Positives:    87\n",
      "  False Negatives:    769\n",
      "  Total Samples:      1743\n",
      "Fold 2/3: Train[0:3498] Val[3522:5271] Test[5295:7044]\n",
      "  Training h=1... ✓ (best_iter=1)\n",
      "  Training h=3... ✓ (best_iter=0)\n",
      "  Training h=6... ✓ (best_iter=1)\n",
      "  Forecasting validation... ✓\n",
      "  Forecasting test... ✓\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 1 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           680                 212\n",
      "Actual Positive           613                 243\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5280\n",
      "  Balanced Accuracy:  0.5231\n",
      "  Precision:          0.5341\n",
      "  Recall (TPR):       0.2839\n",
      "  Specificity (TNR):  0.7623\n",
      "  F1 Score:           0.3707\n",
      "  ROC-AUC:            0.5266\n",
      "  Average Precision:  0.5016\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     243\n",
      "  True Negatives:     680\n",
      "  False Positives:    212\n",
      "  False Negatives:    613\n",
      "  Total Samples:      1748\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 3 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           629                 273\n",
      "Actual Positive           546                 298\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5309\n",
      "  Balanced Accuracy:  0.5252\n",
      "  Precision:          0.5219\n",
      "  Recall (TPR):       0.3531\n",
      "  Specificity (TNR):  0.6973\n",
      "  F1 Score:           0.4212\n",
      "  ROC-AUC:            0.5212\n",
      "  Average Precision:  0.4947\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     298\n",
      "  True Negatives:     629\n",
      "  False Positives:    273\n",
      "  False Negatives:    546\n",
      "  Total Samples:      1746\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 6 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           762                 123\n",
      "Actual Positive           722                 136\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5152\n",
      "  Balanced Accuracy:  0.5098\n",
      "  Precision:          0.5251\n",
      "  Recall (TPR):       0.1585\n",
      "  Specificity (TNR):  0.8610\n",
      "  F1 Score:           0.2435\n",
      "  ROC-AUC:            0.5144\n",
      "  Average Precision:  0.4993\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     136\n",
      "  True Negatives:     762\n",
      "  False Positives:    123\n",
      "  False Negatives:    722\n",
      "  Total Samples:      1743\n",
      "Fold 3/3: Train[0:5247] Val[5271:7020] Test[7044:8747]\n",
      "  Training h=1... ✓ (best_iter=7)\n",
      "  Training h=3... ✓ (best_iter=3)\n",
      "  Training h=6... ✓ (best_iter=11)\n",
      "  Forecasting validation... ✓\n",
      "  Forecasting test... ✓\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 1 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           685                 224\n",
      "Actual Positive           597                 196\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5176\n",
      "  Balanced Accuracy:  0.5004\n",
      "  Precision:          0.4667\n",
      "  Recall (TPR):       0.2472\n",
      "  Specificity (TNR):  0.7536\n",
      "  F1 Score:           0.3232\n",
      "  ROC-AUC:            0.4982\n",
      "  Average Precision:  0.4657\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     196\n",
      "  True Negatives:     685\n",
      "  False Positives:    224\n",
      "  False Negatives:    597\n",
      "  Total Samples:      1702\n",
      "\n",
      "  Generating evaluation plots for horizon 1...\n",
      "  Saved confusion matrix to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/SOL/confusion_matrix_h1.png\n",
      "  Saved ROC curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/SOL/roc_curve_h1.png\n",
      "  Saved PR curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/SOL/precision_recall_h1.png\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 3 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           714                 152\n",
      "Actual Positive           692                 142\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5035\n",
      "  Balanced Accuracy:  0.4974\n",
      "  Precision:          0.4830\n",
      "  Recall (TPR):       0.1703\n",
      "  Specificity (TNR):  0.8245\n",
      "  F1 Score:           0.2518\n",
      "  ROC-AUC:            0.4988\n",
      "  Average Precision:  0.4893\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     142\n",
      "  True Negatives:     714\n",
      "  False Positives:    152\n",
      "  False Negatives:    692\n",
      "  Total Samples:      1700\n",
      "\n",
      "  Generating evaluation plots for horizon 3...\n",
      "  Saved confusion matrix to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/SOL/confusion_matrix_h3.png\n",
      "  Saved ROC curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/SOL/roc_curve_h3.png\n",
      "  Saved PR curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/SOL/precision_recall_h3.png\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 6 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           447                 439\n",
      "Actual Positive           404                 407\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5032\n",
      "  Balanced Accuracy:  0.5032\n",
      "  Precision:          0.4811\n",
      "  Recall (TPR):       0.5018\n",
      "  Specificity (TNR):  0.5045\n",
      "  F1 Score:           0.4912\n",
      "  ROC-AUC:            0.5038\n",
      "  Average Precision:  0.4890\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     407\n",
      "  True Negatives:     447\n",
      "  False Positives:    439\n",
      "  False Negatives:    404\n",
      "  Total Samples:      1697\n",
      "\n",
      "  Generating evaluation plots for horizon 6...\n",
      "  Saved confusion matrix to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/SOL/confusion_matrix_h6.png\n",
      "  Saved ROC curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/SOL/roc_curve_h6.png\n",
      "  Saved PR curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/SOL/precision_recall_h6.png\n",
      "\n",
      "Completed SOL\n",
      "\n",
      "\n",
      "============================================================\n",
      "SUMMARY FOR SOL\n",
      "============================================================\n",
      "\n",
      "Horizon 1:\n",
      "  Test samples:      5198\n",
      "  Accuracy:          0.5173\n",
      "  Balanced Acc:      0.5099\n",
      "  Precision:         0.5558\n",
      "  Recall:            0.1854\n",
      "  F1 Score:          0.2475\n",
      "  ROC-AUC:           0.5109\n",
      "  Brier Score:       0.2480\n",
      "  ECE:               0.0000\n",
      "\n",
      "Horizon 3:\n",
      "  Test samples:      5192\n",
      "  Accuracy:          0.5126\n",
      "  Balanced Acc:      0.5095\n",
      "  Precision:         0.5163\n",
      "  Recall:            0.2003\n",
      "  F1 Score:          0.2695\n",
      "  ROC-AUC:           0.5129\n",
      "  Brier Score:       0.2471\n",
      "  ECE:               0.0000\n",
      "\n",
      "Horizon 6:\n",
      "  Test samples:      5183\n",
      "  Accuracy:          0.5091\n",
      "  Balanced Acc:      0.5094\n",
      "  Precision:         0.5266\n",
      "  Recall:            0.2641\n",
      "  F1 Score:          0.3165\n",
      "  ROC-AUC:           0.5125\n",
      "  Brier Score:       0.2467\n",
      "  ECE:               0.0000\n",
      "\n",
      "============================================================\n",
      "Training XGBoost for XRP\n",
      "Horizons: [1, 3, 6]\n",
      "Folds: 3\n",
      "Params: n_estimators=100, max_depth=6, lr=0.1\n",
      "============================================================\n",
      "\n",
      "Fold 1/3: Train[0:1749] Val[1773:3522] Test[3546:5295]\n",
      "  Training h=1... ✓ (best_iter=2)\n",
      "  Training h=3... ✓ (best_iter=4)\n",
      "  Training h=6... ✓ (best_iter=3)\n",
      "\n",
      "============================================================\n",
      "FEATURE IMPORTANCE ANALYSIS (XGBoost)\n",
      "============================================================\n",
      "\n",
      "Note: 'Gain' measures average improvement in loss when splitting on feature.\n",
      "Higher gain = more important for predictions.\n",
      "\n",
      "\n",
      "Horizon 1 (best iteration: 2):\n",
      "  Top Features by Gain:\n",
      "    1. ret_3          :     3.94 ( 19.5%)\n",
      "    2. ret_6          :     3.79 ( 18.8%)\n",
      "    3. vol_12         :     3.28 ( 16.2%)\n",
      "    4. ret_1          :     3.14 ( 15.5%)\n",
      "    5. vol_6          :     3.11 ( 15.4%)\n",
      "    6. ma_ratio       :     2.96 ( 14.6%)\n",
      "\n",
      "Horizon 3 (best iteration: 4):\n",
      "  Top Features by Gain:\n",
      "    1. ma_ratio       :     4.71 ( 20.4%)\n",
      "    2. ret_6          :     4.56 ( 19.8%)\n",
      "    3. vol_12         :     3.88 ( 16.8%)\n",
      "    4. ret_3          :     3.54 ( 15.3%)\n",
      "    5. vol_6          :     3.53 ( 15.3%)\n",
      "    6. ret_1          :     2.86 ( 12.4%)\n",
      "\n",
      "Horizon 6 (best iteration: 3):\n",
      "  Top Features by Gain:\n",
      "    1. ma_ratio       :     4.79 ( 18.7%)\n",
      "    2. vol_12         :     4.68 ( 18.3%)\n",
      "    3. ret_3          :     4.63 ( 18.1%)\n",
      "    4. ret_6          :     4.38 ( 17.1%)\n",
      "    5. vol_6          :     3.88 ( 15.2%)\n",
      "    6. ret_1          :     3.23 ( 12.6%)\n",
      "  Forecasting validation... ✓\n",
      "  Forecasting test... ✓\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 1 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           762                 195\n",
      "Actual Positive           607                 184\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5412\n",
      "  Balanced Accuracy:  0.5144\n",
      "  Precision:          0.4855\n",
      "  Recall (TPR):       0.2326\n",
      "  Specificity (TNR):  0.7962\n",
      "  F1 Score:           0.3145\n",
      "  ROC-AUC:            0.5179\n",
      "  Average Precision:  0.4641\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     184\n",
      "  True Negatives:     762\n",
      "  False Positives:    195\n",
      "  False Negatives:    607\n",
      "  Total Samples:      1748\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 3 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           820                 118\n",
      "Actual Positive           718                  90\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5212\n",
      "  Balanced Accuracy:  0.4928\n",
      "  Precision:          0.4327\n",
      "  Recall (TPR):       0.1114\n",
      "  Specificity (TNR):  0.8742\n",
      "  F1 Score:           0.1772\n",
      "  ROC-AUC:            0.4891\n",
      "  Average Precision:  0.4568\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     90\n",
      "  True Negatives:     820\n",
      "  False Positives:    118\n",
      "  False Negatives:    718\n",
      "  Total Samples:      1746\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 6 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           660                 286\n",
      "Actual Positive           525                 272\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5347\n",
      "  Balanced Accuracy:  0.5195\n",
      "  Precision:          0.4875\n",
      "  Recall (TPR):       0.3413\n",
      "  Specificity (TNR):  0.6977\n",
      "  F1 Score:           0.4015\n",
      "  ROC-AUC:            0.5213\n",
      "  Average Precision:  0.4700\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     272\n",
      "  True Negatives:     660\n",
      "  False Positives:    286\n",
      "  False Negatives:    525\n",
      "  Total Samples:      1743\n",
      "Fold 2/3: Train[0:3498] Val[3522:5271] Test[5295:7044]\n",
      "  Training h=1... ✓ (best_iter=5)\n",
      "  Training h=3... ✓ (best_iter=5)\n",
      "  Training h=6... ✓ (best_iter=2)\n",
      "  Forecasting validation... ✓\n",
      "  Forecasting test... ✓\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 1 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           741                 161\n",
      "Actual Positive           682                 164\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5177\n",
      "  Balanced Accuracy:  0.5077\n",
      "  Precision:          0.5046\n",
      "  Recall (TPR):       0.1939\n",
      "  Specificity (TNR):  0.8215\n",
      "  F1 Score:           0.2801\n",
      "  ROC-AUC:            0.5397\n",
      "  Average Precision:  0.5040\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     164\n",
      "  True Negatives:     741\n",
      "  False Positives:    161\n",
      "  False Negatives:    682\n",
      "  Total Samples:      1748\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 3 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           655                 218\n",
      "Actual Positive           631                 242\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5137\n",
      "  Balanced Accuracy:  0.5137\n",
      "  Precision:          0.5261\n",
      "  Recall (TPR):       0.2772\n",
      "  Specificity (TNR):  0.7503\n",
      "  F1 Score:           0.3631\n",
      "  ROC-AUC:            0.5198\n",
      "  Average Precision:  0.5111\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     242\n",
      "  True Negatives:     655\n",
      "  False Positives:    218\n",
      "  False Negatives:    631\n",
      "  Total Samples:      1746\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 6 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           737                 136\n",
      "Actual Positive           680                 190\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5318\n",
      "  Balanced Accuracy:  0.5313\n",
      "  Precision:          0.5828\n",
      "  Recall (TPR):       0.2184\n",
      "  Specificity (TNR):  0.8442\n",
      "  F1 Score:           0.3177\n",
      "  ROC-AUC:            0.5300\n",
      "  Average Precision:  0.5184\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     190\n",
      "  True Negatives:     737\n",
      "  False Positives:    136\n",
      "  False Negatives:    680\n",
      "  Total Samples:      1743\n",
      "Fold 3/3: Train[0:5247] Val[5271:7020] Test[7044:8747]\n",
      "  Training h=1... ✓ (best_iter=4)\n",
      "  Training h=3... ✓ (best_iter=0)\n",
      "  Training h=6... ✓ (best_iter=1)\n",
      "  Forecasting validation... ✓\n",
      "  Forecasting test... ✓\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 1 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           731                 173\n",
      "Actual Positive           589                 209\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5523\n",
      "  Balanced Accuracy:  0.5353\n",
      "  Precision:          0.5471\n",
      "  Recall (TPR):       0.2619\n",
      "  Specificity (TNR):  0.8086\n",
      "  F1 Score:           0.3542\n",
      "  ROC-AUC:            0.5455\n",
      "  Average Precision:  0.5024\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     209\n",
      "  True Negatives:     731\n",
      "  False Positives:    173\n",
      "  False Negatives:    589\n",
      "  Total Samples:      1702\n",
      "\n",
      "  Generating evaluation plots for horizon 1...\n",
      "  Saved confusion matrix to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/XRP/confusion_matrix_h1.png\n",
      "  Saved ROC curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/XRP/roc_curve_h1.png\n",
      "  Saved PR curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/XRP/precision_recall_h1.png\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 3 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           280                 603\n",
      "Actual Positive           243                 574\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5024\n",
      "  Balanced Accuracy:  0.5098\n",
      "  Precision:          0.4877\n",
      "  Recall (TPR):       0.7026\n",
      "  Specificity (TNR):  0.3171\n",
      "  F1 Score:           0.5757\n",
      "  ROC-AUC:            0.5288\n",
      "  Average Precision:  0.5082\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     574\n",
      "  True Negatives:     280\n",
      "  False Positives:    603\n",
      "  False Negatives:    243\n",
      "  Total Samples:      1700\n",
      "\n",
      "  Generating evaluation plots for horizon 3...\n",
      "  Saved confusion matrix to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/XRP/confusion_matrix_h3.png\n",
      "  Saved ROC curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/XRP/roc_curve_h3.png\n",
      "  Saved PR curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/XRP/precision_recall_h3.png\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 6 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           561                 353\n",
      "Actual Positive           422                 361\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5433\n",
      "  Balanced Accuracy:  0.5374\n",
      "  Precision:          0.5056\n",
      "  Recall (TPR):       0.4610\n",
      "  Specificity (TNR):  0.6138\n",
      "  F1 Score:           0.4823\n",
      "  ROC-AUC:            0.5418\n",
      "  Average Precision:  0.4923\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     361\n",
      "  True Negatives:     561\n",
      "  False Positives:    353\n",
      "  False Negatives:    422\n",
      "  Total Samples:      1697\n",
      "\n",
      "  Generating evaluation plots for horizon 6...\n",
      "  Saved confusion matrix to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/XRP/confusion_matrix_h6.png\n",
      "  Saved ROC curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/XRP/roc_curve_h6.png\n",
      "  Saved PR curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/XRP/precision_recall_h6.png\n",
      "\n",
      "Completed XRP\n",
      "\n",
      "\n",
      "============================================================\n",
      "SUMMARY FOR XRP\n",
      "============================================================\n",
      "\n",
      "Horizon 1:\n",
      "  Test samples:      5198\n",
      "  Accuracy:          0.5371\n",
      "  Balanced Acc:      0.5191\n",
      "  Precision:         0.5124\n",
      "  Recall:            0.2295\n",
      "  F1 Score:          0.3163\n",
      "  ROC-AUC:           0.5344\n",
      "  Brier Score:       0.2463\n",
      "  ECE:               0.0000\n",
      "\n",
      "Horizon 3:\n",
      "  Test samples:      5192\n",
      "  Accuracy:          0.5124\n",
      "  Balanced Acc:      0.5055\n",
      "  Precision:         0.4822\n",
      "  Recall:            0.3637\n",
      "  F1 Score:          0.3720\n",
      "  ROC-AUC:           0.5126\n",
      "  Brier Score:       0.2470\n",
      "  ECE:               0.0000\n",
      "\n",
      "Horizon 6:\n",
      "  Test samples:      5183\n",
      "  Accuracy:          0.5366\n",
      "  Balanced Acc:      0.5294\n",
      "  Precision:         0.5253\n",
      "  Recall:            0.3402\n",
      "  F1 Score:          0.4005\n",
      "  ROC-AUC:           0.5310\n",
      "  Brier Score:       0.2461\n",
      "  ECE:               0.0000\n",
      "\n",
      "============================================================\n",
      "Training XGBoost for DOGE\n",
      "Horizons: [1, 3, 6]\n",
      "Folds: 3\n",
      "Params: n_estimators=100, max_depth=6, lr=0.1\n",
      "============================================================\n",
      "\n",
      "Fold 1/3: Train[0:1749] Val[1773:3522] Test[3546:5295]\n",
      "  Training h=1... ✓ (best_iter=5)\n",
      "  Training h=3... ✓ (best_iter=2)\n",
      "  Training h=6... ✓ (best_iter=3)\n",
      "\n",
      "============================================================\n",
      "FEATURE IMPORTANCE ANALYSIS (XGBoost)\n",
      "============================================================\n",
      "\n",
      "Note: 'Gain' measures average improvement in loss when splitting on feature.\n",
      "Higher gain = more important for predictions.\n",
      "\n",
      "\n",
      "Horizon 1 (best iteration: 5):\n",
      "  Top Features by Gain:\n",
      "    1. ret_6          :     3.92 ( 19.8%)\n",
      "    2. vol_12         :     3.24 ( 16.4%)\n",
      "    3. ret_1          :     3.23 ( 16.4%)\n",
      "    4. ret_3          :     3.17 ( 16.1%)\n",
      "    5. vol_6          :     3.15 ( 16.0%)\n",
      "    6. ma_ratio       :     3.04 ( 15.4%)\n",
      "\n",
      "Horizon 3 (best iteration: 2):\n",
      "  Top Features by Gain:\n",
      "    1. ret_6          :     4.84 ( 19.6%)\n",
      "    2. ma_ratio       :     4.58 ( 18.6%)\n",
      "    3. vol_12         :     4.12 ( 16.7%)\n",
      "    4. vol_6          :     3.86 ( 15.6%)\n",
      "    5. ret_3          :     3.68 ( 14.9%)\n",
      "    6. ret_1          :     3.59 ( 14.5%)\n",
      "\n",
      "Horizon 6 (best iteration: 3):\n",
      "  Top Features by Gain:\n",
      "    1. ret_6          :     6.10 ( 22.2%)\n",
      "    2. ma_ratio       :     4.83 ( 17.6%)\n",
      "    3. vol_12         :     4.79 ( 17.4%)\n",
      "    4. vol_6          :     4.41 ( 16.1%)\n",
      "    5. ret_3          :     4.40 ( 16.0%)\n",
      "    6. ret_1          :     2.94 ( 10.7%)\n",
      "  Forecasting validation... ✓\n",
      "  Forecasting test... ✓\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 1 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           641                 269\n",
      "Actual Positive           554                 284\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5292\n",
      "  Balanced Accuracy:  0.5216\n",
      "  Precision:          0.5136\n",
      "  Recall (TPR):       0.3389\n",
      "  Specificity (TNR):  0.7044\n",
      "  F1 Score:           0.4083\n",
      "  ROC-AUC:            0.5299\n",
      "  Average Precision:  0.4973\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     284\n",
      "  True Negatives:     641\n",
      "  False Positives:    269\n",
      "  False Negatives:    554\n",
      "  Total Samples:      1748\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 3 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           784                 117\n",
      "Actual Positive           675                 170\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5464\n",
      "  Balanced Accuracy:  0.5357\n",
      "  Precision:          0.5923\n",
      "  Recall (TPR):       0.2012\n",
      "  Specificity (TNR):  0.8701\n",
      "  F1 Score:           0.3004\n",
      "  ROC-AUC:            0.5484\n",
      "  Average Precision:  0.5170\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     170\n",
      "  True Negatives:     784\n",
      "  False Positives:    117\n",
      "  False Negatives:    675\n",
      "  Total Samples:      1746\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 6 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           758                 132\n",
      "Actual Positive           693                 160\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5267\n",
      "  Balanced Accuracy:  0.5196\n",
      "  Precision:          0.5479\n",
      "  Recall (TPR):       0.1876\n",
      "  Specificity (TNR):  0.8517\n",
      "  F1 Score:           0.2795\n",
      "  ROC-AUC:            0.5489\n",
      "  Average Precision:  0.5196\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     160\n",
      "  True Negatives:     758\n",
      "  False Positives:    132\n",
      "  False Negatives:    693\n",
      "  Total Samples:      1743\n",
      "Fold 2/3: Train[0:3498] Val[3522:5271] Test[5295:7044]\n",
      "  Training h=1... ✓ (best_iter=12)\n",
      "  Training h=3... ✓ (best_iter=7)\n",
      "  Training h=6... ✓ (best_iter=4)\n",
      "  Forecasting validation... ✓\n",
      "  Forecasting test... ✓\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 1 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           645                 244\n",
      "Actual Positive           566                 293\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5366\n",
      "  Balanced Accuracy:  0.5333\n",
      "  Precision:          0.5456\n",
      "  Recall (TPR):       0.3411\n",
      "  Specificity (TNR):  0.7255\n",
      "  F1 Score:           0.4198\n",
      "  ROC-AUC:            0.5403\n",
      "  Average Precision:  0.5203\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     293\n",
      "  True Negatives:     645\n",
      "  False Positives:    244\n",
      "  False Negatives:    566\n",
      "  Total Samples:      1748\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 3 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           538                 340\n",
      "Actual Positive           500                 368\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5189\n",
      "  Balanced Accuracy:  0.5184\n",
      "  Precision:          0.5198\n",
      "  Recall (TPR):       0.4240\n",
      "  Specificity (TNR):  0.6128\n",
      "  F1 Score:           0.4670\n",
      "  ROC-AUC:            0.5121\n",
      "  Average Precision:  0.5032\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     368\n",
      "  True Negatives:     538\n",
      "  False Positives:    340\n",
      "  False Negatives:    500\n",
      "  Total Samples:      1746\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 6 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           471                 402\n",
      "Actual Positive           478                 392\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.4951\n",
      "  Balanced Accuracy:  0.4950\n",
      "  Precision:          0.4937\n",
      "  Recall (TPR):       0.4506\n",
      "  Specificity (TNR):  0.5395\n",
      "  F1 Score:           0.4712\n",
      "  ROC-AUC:            0.4887\n",
      "  Average Precision:  0.4948\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     392\n",
      "  True Negatives:     471\n",
      "  False Positives:    402\n",
      "  False Negatives:    478\n",
      "  Total Samples:      1743\n",
      "Fold 3/3: Train[0:5247] Val[5271:7020] Test[7044:8747]\n",
      "  Training h=1... ✓ (best_iter=2)\n",
      "  Training h=3... ✓ (best_iter=0)\n",
      "  Training h=6... ✓ (best_iter=0)\n",
      "  Forecasting validation... ✓\n",
      "  Forecasting test... ✓\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 1 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           492                 398\n",
      "Actual Positive           424                 388\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.5170\n",
      "  Balanced Accuracy:  0.5153\n",
      "  Precision:          0.4936\n",
      "  Recall (TPR):       0.4778\n",
      "  Specificity (TNR):  0.5528\n",
      "  F1 Score:           0.4856\n",
      "  ROC-AUC:            0.5234\n",
      "  Average Precision:  0.5040\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     388\n",
      "  True Negatives:     492\n",
      "  False Positives:    398\n",
      "  False Negatives:    424\n",
      "  Total Samples:      1702\n",
      "\n",
      "  Generating evaluation plots for horizon 1...\n",
      "  Saved confusion matrix to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/DOGE/confusion_matrix_h1.png\n",
      "  Saved ROC curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/DOGE/roc_curve_h1.png\n",
      "  Saved PR curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/DOGE/precision_recall_h1.png\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 3 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative           503                 377\n",
      "Actual Positive           489                 331\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.4906\n",
      "  Balanced Accuracy:  0.4876\n",
      "  Precision:          0.4675\n",
      "  Recall (TPR):       0.4037\n",
      "  Specificity (TNR):  0.5716\n",
      "  F1 Score:           0.4332\n",
      "  ROC-AUC:            0.4940\n",
      "  Average Precision:  0.4838\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     331\n",
      "  True Negatives:     503\n",
      "  False Positives:    377\n",
      "  False Negatives:    489\n",
      "  Total Samples:      1700\n",
      "\n",
      "  Generating evaluation plots for horizon 3...\n",
      "  Saved confusion matrix to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/DOGE/confusion_matrix_h3.png\n",
      "  Saved ROC curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/DOGE/roc_curve_h3.png\n",
      "  Saved PR curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/DOGE/precision_recall_h3.png\n",
      "\n",
      "============================================================\n",
      "CLASSIFICATION METRICS - Horizon 6 (test)\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Negative  Predicted Positive\n",
      "Actual Negative            10                 880\n",
      "Actual Positive             6                 801\n",
      "\n",
      "Performance Metrics:\n",
      "  Accuracy:           0.4779\n",
      "  Balanced Accuracy:  0.5019\n",
      "  Precision:          0.4765\n",
      "  Recall (TPR):       0.9926\n",
      "  Specificity (TNR):  0.0112\n",
      "  F1 Score:           0.6439\n",
      "  ROC-AUC:            0.5135\n",
      "  Average Precision:  0.4832\n",
      "\n",
      "Detailed Counts:\n",
      "  True Positives:     801\n",
      "  True Negatives:     10\n",
      "  False Positives:    880\n",
      "  False Negatives:    6\n",
      "  Total Samples:      1697\n",
      "\n",
      "  Generating evaluation plots for horizon 6...\n",
      "  Saved confusion matrix to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/DOGE/confusion_matrix_h6.png\n",
      "  Saved ROC curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/DOGE/roc_curve_h6.png\n",
      "  Saved PR curve to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots/DOGE/precision_recall_h6.png\n",
      "\n",
      "Completed DOGE\n",
      "\n",
      "\n",
      "============================================================\n",
      "SUMMARY FOR DOGE\n",
      "============================================================\n",
      "\n",
      "Horizon 1:\n",
      "  Test samples:      5198\n",
      "  Accuracy:          0.5276\n",
      "  Balanced Acc:      0.5234\n",
      "  Precision:         0.5176\n",
      "  Recall:            0.3859\n",
      "  F1 Score:          0.4379\n",
      "  ROC-AUC:           0.5312\n",
      "  Brier Score:       0.2456\n",
      "  ECE:               0.0000\n",
      "\n",
      "Horizon 3:\n",
      "  Test samples:      5192\n",
      "  Accuracy:          0.5186\n",
      "  Balanced Acc:      0.5139\n",
      "  Precision:         0.5265\n",
      "  Recall:            0.3429\n",
      "  F1 Score:          0.4002\n",
      "  ROC-AUC:           0.5182\n",
      "  Brier Score:       0.2474\n",
      "  ECE:               0.0000\n",
      "\n",
      "Horizon 6:\n",
      "  Test samples:      5183\n",
      "  Accuracy:          0.4999\n",
      "  Balanced Acc:      0.5055\n",
      "  Precision:         0.5061\n",
      "  Recall:            0.5436\n",
      "  F1 Score:          0.4648\n",
      "  ROC-AUC:           0.5171\n",
      "  Brier Score:       0.2476\n",
      "  ECE:               0.0000\n",
      "\n",
      "Saved metrics summary to: /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/xgb_metrics_summary.csv\n",
      "\n",
      "============================================================\n",
      "OVERALL METRICS SUMMARY (across all symbols and horizons)\n",
      "============================================================\n",
      "       accuracy  balanced_accuracy  precision   recall  f1_score  roc_auc  \\\n",
      "count   15.0000            15.0000    15.0000  15.0000   15.0000  15.0000   \n",
      "mean     0.5204             0.5109     0.4988   0.2747    0.3139   0.5172   \n",
      "std      0.0129             0.0081     0.0511   0.1317    0.1075   0.0100   \n",
      "min      0.4999             0.5005     0.3275   0.0552    0.0930   0.5035   \n",
      "25%      0.5125             0.5055     0.4958   0.1928    0.2564   0.5115   \n",
      "50%      0.5186             0.5094     0.5110   0.2641    0.3163   0.5129   \n",
      "75%      0.5308             0.5150     0.5215   0.3533    0.4004   0.5246   \n",
      "max      0.5424             0.5294     0.5558   0.5436    0.4648   0.5344   \n",
      "\n",
      "       brier_score   ece  \n",
      "count      15.0000  15.0  \n",
      "mean        0.2466   0.0  \n",
      "std         0.0011   0.0  \n",
      "min         0.2446   0.0  \n",
      "25%         0.2459   0.0  \n",
      "50%         0.2467   0.0  \n",
      "75%         0.2472   0.0  \n",
      "max         0.2483   0.0  \n",
      "\n",
      "============================================================\n",
      "FINAL OUTPUTS\n",
      "============================================================\n",
      "JSON feed:        /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/trader_feed_xgb_multiH.jsonl\n",
      "Metrics CSV:      /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/xgb_metrics_summary.csv\n",
      "Plots directory:  /Users/nitinlodha/Desktop/ML/ML_Project/Bybit_CSV_Data/evaluation_plots\n",
      "============================================================\n",
      "\n",
      "💡 Tip: XGBoost typically achieves the best accuracy!\n",
      "Compare with other models using the metrics CSV files.\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# MAIN EXECUTION\n",
    "# =========================================\n",
    "if __name__ == \"__main__\":\n",
    "    if not XGBOOST_AVAILABLE:\n",
    "        print(\"\\nERROR: XGBoost is not installed!\")\n",
    "        print(\"Please install with: pip install xgboost\")\n",
    "        print(\"Then run this script again.\\n\")\n",
    "        exit(1)\n",
    "\n",
    "    # Process all symbols\n",
    "    all_outputs = {}\n",
    "    all_metrics = {}\n",
    "\n",
    "    for symbol, path in FILES.items():\n",
    "        if not path.exists():\n",
    "            print(f\"Warning: {path} not found, skipping {symbol}\")\n",
    "            continue\n",
    "\n",
    "        results = run_xgb_for_symbol(\n",
    "            symbol=symbol,\n",
    "            path=path,\n",
    "            horizons=HORIZONS,\n",
    "            n_folds=3,\n",
    "            embargo=24,\n",
    "            n_estimators=100,      # Try: 50 (faster), 200 (more accurate)\n",
    "            max_depth=6,           # Try: 3-4 (less overfit), 8-10 (more complex)\n",
    "            learning_rate=0.1,     # Try: 0.01-0.05 (slower learning), 0.2-0.3 (faster)\n",
    "            early_stopping=True,   # Recommended: prevents overfitting\n",
    "            save_plots=True\n",
    "        )\n",
    "\n",
    "        all_outputs[symbol] = results\n",
    "\n",
    "        # Collect metrics\n",
    "        all_metrics[symbol] = {}\n",
    "        for h in HORIZONS:\n",
    "            if results[h]['metrics']:\n",
    "                metrics_list = results[h]['metrics']\n",
    "                avg_metrics = {\n",
    "                    'accuracy': np.mean([m['accuracy'] for m in metrics_list]),\n",
    "                    'balanced_accuracy': np.mean([m['balanced_accuracy'] for m in metrics_list]),\n",
    "                    'precision': np.mean([m['precision'] for m in metrics_list]),\n",
    "                    'recall': np.mean([m['recall'] for m in metrics_list]),\n",
    "                    'specificity': np.mean([m['specificity'] for m in metrics_list]),\n",
    "                    'f1_score': np.mean([m['f1_score'] for m in metrics_list]),\n",
    "                    'roc_auc': np.mean([m['roc_auc'] for m in metrics_list if m.get('roc_auc') is not None]),\n",
    "                    'average_precision': np.mean([m['average_precision'] for m in metrics_list if m.get('average_precision') is not None]),\n",
    "                    'true_positives': sum([m['true_positives'] for m in metrics_list]),\n",
    "                    'false_positives': sum([m['false_positives'] for m in metrics_list]),\n",
    "                    'true_negatives': sum([m['true_negatives'] for m in metrics_list]),\n",
    "                    'false_negatives': sum([m['false_negatives'] for m in metrics_list]),\n",
    "                }\n",
    "\n",
    "                diag_list = results[h]['diag']\n",
    "                if diag_list:\n",
    "                    avg_metrics['brier_val'] = np.mean([d['brier_val'] for d in diag_list])\n",
    "                    avg_metrics['ece_val'] = np.mean([d['ece_val'] for d in diag_list])\n",
    "\n",
    "                all_metrics[symbol][h] = avg_metrics\n",
    "\n",
    "        # Print summary\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"SUMMARY FOR {symbol}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        for h in HORIZONS:\n",
    "            test_df = results[h]['test']\n",
    "\n",
    "            if len(test_df) > 0 and h in all_metrics[symbol]:\n",
    "                metrics = all_metrics[symbol][h]\n",
    "                print(f\"\\nHorizon {h}:\")\n",
    "                print(f\"  Test samples:      {len(test_df)}\")\n",
    "                print(f\"  Accuracy:          {metrics['accuracy']:.4f}\")\n",
    "                print(f\"  Balanced Acc:      {metrics['balanced_accuracy']:.4f}\")\n",
    "                print(f\"  Precision:         {metrics['precision']:.4f}\")\n",
    "                print(f\"  Recall:            {metrics['recall']:.4f}\")\n",
    "                print(f\"  F1 Score:          {metrics['f1_score']:.4f}\")\n",
    "                if not np.isnan(metrics.get('roc_auc', np.nan)):\n",
    "                    print(f\"  ROC-AUC:           {metrics['roc_auc']:.4f}\")\n",
    "                print(f\"  Brier Score:       {metrics.get('brier_val', np.nan):.4f}\")\n",
    "                print(f\"  ECE:               {metrics.get('ece_val', np.nan):.4f}\")\n",
    "\n",
    "    # Save metrics summary\n",
    "    metrics_csv_path = DATA_DIR / \"xgb_metrics_summary.csv\"\n",
    "    save_metrics_to_csv(all_metrics, metrics_csv_path)\n",
    "\n",
    "    # Export to JSON\n",
    "    json_records = build_json_records(all_outputs)\n",
    "    json_path = DATA_DIR / \"trader_feed_xgb_multiH.jsonl\"\n",
    "    with open(json_path, \"w\") as f:\n",
    "        for r in json_records:\n",
    "            f.write(json.dumps(r) + \"\\n\")\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FINAL OUTPUTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"JSON feed:        {json_path}\")\n",
    "    print(f\"Metrics CSV:      {metrics_csv_path}\")\n",
    "    print(f\"Plots directory:  {DATA_DIR / 'evaluation_plots'}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    print(\"💡 Tip: XGBoost typically achieves the best accuracy!\")\n",
    "    print(\"Compare with other models using the metrics CSV files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d805eec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
