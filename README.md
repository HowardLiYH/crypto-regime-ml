# Comparative Evaluation of Machine Learning Models for Cryptocurrency Trading Signal Generation

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **A Walk-Forward Analysis with Regime Enhancement**

This repository contains the code, data, and pre-trained models for our comprehensive evaluation of **19 machine learning models** across **5 major cryptocurrencies** using rigorous walk-forward cross-validation with temporal embargo.

---

## ğŸ“Š Key Findings

| Finding | Detail |
|---------|--------|
| **Regime-Conditional Asymmetry** | ML models beat buy-and-hold in **100% of bear markets** but **<1% of bull markets** |
| **Accuracy â‰  Profit** | Correlation between accuracy and P&L is **r = -0.014** (essentially zero) |
| **Best Accuracy** | Random Forest (52.57%) |
| **Best P&L** | GRU+Combined_Regime (+29.48 cumulative) |
| **K-Fold Inflation** | Standard k-fold CV inflates accuracy by **+3.16%** vs walk-forward |

**Central Thesis:** ML models serve primarily as **defensive instruments for risk management** rather than alpha generators.

---

## ğŸ—ï¸ Repository Structure

```
crypto-regime-ml/
â”œâ”€â”€ model_eval_reorganized.ipynb   # Main evaluation notebook (17 experiments)
â”œâ”€â”€ final_report.tex               # NeurIPS-style paper
â”œâ”€â”€ Base_Models/                   # Individual model implementations
â”‚   â”œâ”€â”€ RF.ipynb                   # Random Forest
â”‚   â”œâ”€â”€ SVM.ipynb                  # Support Vector Machine
â”‚   â”œâ”€â”€ XGBoost.ipynb              # Gradient Boosting
â”‚   â”œâ”€â”€ GRU.ipynb                  # Gated Recurrent Unit
â”‚   â””â”€â”€ PCA+HMM.ipynb              # PCA + Hidden Markov Model
â”œâ”€â”€ Bybit_CSV_Data/                # Historical OHLCV data
â”‚   â”œâ”€â”€ Bybit_BTC.csv
â”‚   â”œâ”€â”€ Bybit_ETH.csv
â”‚   â”œâ”€â”€ Bybit_SOL.csv
â”‚   â”œâ”€â”€ Bybit_XRP.csv
â”‚   â””â”€â”€ Bybit_DOGE.csv
â”œâ”€â”€ plots/                         # All experiment visualizations
â”‚   â”œâ”€â”€ section_6/                 # Methodology validation
â”‚   â”œâ”€â”€ section_7/                 # Comparative analysis
â”‚   â”œâ”€â”€ section_8/                 # Economic performance
â”‚   â”œâ”€â”€ section_9/                 # Statistical validation
â”‚   â”œâ”€â”€ section_10/                # Model interpretability
â”‚   â””â”€â”€ section_12/                # Asset-specific performance
â”œâ”€â”€ saved_models/                  # Pre-trained model artifacts
â”‚   â””â”€â”€ evaluation_results.pkl
â””â”€â”€ README.md
```

---

## ğŸ“ˆ Models Evaluated

### Base Models (5)
- **Random Forest (RF)** - Ensemble of decision trees with bootstrap aggregation
- **Support Vector Machine (SVM)** - RBF kernel with Platt scaling
- **XGBoost** - Gradient boosting with regularization
- **GRU** - Gated Recurrent Unit for temporal patterns
- **PCA+HMM** - Dimensionality reduction with Hidden Markov Model

### Regime-Enhanced Variants (12)
Each base model augmented with:
- **HMM Regime** - Latent state probabilities from Gaussian HMM
- **Technical Regime** - Volatility percentile, trend, momentum indicators
- **Combined Regime** - Both HMM and technical features

### Benchmarks (2)
- **Naive Bayes** - Gaussian feature independence assumption
- **Martingale** - Random walk baseline (always predicts 50%)

---

## ğŸ”¬ Experiments

| Section | Experiments | Focus |
|---------|-------------|-------|
| **6** | 6.1-6.6 | Methodology validation (cost-awareness, calibration, embargo) |
| **7** | 7.1-7.4 | Comparative model analysis (volatility, reversals, consistency) |
| **8** | 8.1-8.4 | Economic performance (Sharpe, Sortino, drawdown, efficiency) |
| **9** | 9.1-9.3 | Statistical validation (significance, effect size, confidence intervals) |
| **10** | 10.1-10.2 | Model interpretability (feature importance, calibration curves) |
| **12** | 12.1-12.5 | Asset-specific performance (BTC, ETH, SOL, XRP, DOGE) |

---

## ğŸ› ï¸ Installation

### Requirements

```bash
pip install numpy pandas scikit-learn xgboost torch matplotlib seaborn hmmlearn
```

### Dependencies
- Python 3.8+
- NumPy â‰¥ 1.21
- Pandas â‰¥ 1.3
- Scikit-learn â‰¥ 1.0
- XGBoost â‰¥ 1.5
- PyTorch â‰¥ 1.10
- hmmlearn â‰¥ 0.2.7
- Matplotlib â‰¥ 3.5
- Seaborn â‰¥ 0.11

---

## ğŸš€ Usage

### Quick Start

```python
# Load evaluation results
import pickle

with open('saved_models/evaluation_results.pkl', 'rb') as f:
    results = pickle.load(f)

# Access model performance
df_results = results['df_results']
print(df_results.groupby('model')['accuracy'].mean().sort_values(ascending=False))
```

### Run Full Evaluation

Open `model_eval_reorganized.ipynb` in Jupyter and execute all cells sequentially.

---

## ğŸ“ Data Description

| Asset | Samples | Period | Frequency |
|-------|---------|--------|-----------|
| BTC | ~8,767 | Nov 2021 - Nov 2025 | 4-hour |
| ETH | ~8,767 | Nov 2021 - Nov 2025 | 4-hour |
| SOL | ~8,767 | Nov 2021 - Nov 2025 | 4-hour |
| XRP | ~8,767 | Nov 2021 - Nov 2025 | 4-hour |
| DOGE | ~8,767 | Nov 2021 - Nov 2025 | 4-hour |

**Features (11 total):**
- **Technical (6):** ret_1, ret_3, ret_6, vol_6, vol_12, ma_ratio
- **Microstructure (5):** funding_rate, funding_zscore, ls_ratio, ls_ratio_change, oi_change_pct

---

## ğŸ“ Methodology

### Walk-Forward Cross-Validation

```
    2021      2022      2023      2024      2025
    |         |         |         |         |
    Nov       Aug       Jun       Apr       Nov
    |---------|---------|---------|---------|
    |                                       |
    | FOLD 1: Train---->                    |
    |                   Test----------->    |
    |                                       |
    | FOLD 2: Train------------>            |
    |                           Test------> |
    |                                       |
    | FOLD 3: Train------------------>      |
    |                                 Test->|
    |---------|---------|---------|---------|
```

- **Embargo:** 24-bar (96-hour) gap between train/test
- **Cost-Aware Targets:** Predict return > transaction cost (8-12 bp)

---

## ğŸ“– Citation

If you use this code or data in your research, please cite:

```bibtex
@article{li2025crypto,
  title={Comparative Evaluation of Machine Learning Models for Cryptocurrency Trading Signal Generation: A Walk-Forward Analysis with Regime Enhancement},
  author={Li, Howard and Lodha, Nitin and Bokdia, Akshat},
  journal={CIS 5200: Machine Learning, University of Pennsylvania},
  year={2025}
}
```

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Course:** CIS 5200: Machine Learning, University of Pennsylvania
- **Instructor:** Prof. Lyle Ungar
- **Data Source:** Bybit Exchange API

---

## ğŸ“§ Contact

- Howard Li - li88@sas.upenn.edu
- Nitin Lodha - lodha1@seas.upenn.edu
- Akshat Bokdia - abokdia@seas.upenn.edu
